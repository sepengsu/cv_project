{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac12718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import shutil # shutil 모듈을 사용하여 파일 및 디렉토리 복사, 이동, 삭제 등을 수행할 수 있습니다.\n",
    "DIR1 = './results/temp_1'\n",
    "DIR2 = './results/temp_2'\n",
    "DIR = '_'.join(DIR1.split('_')[:-1])\n",
    "DIR = DIR.replace('temp', 'latency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1cc691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./results/latency already exists. Removing it and creating a new one.\n"
     ]
    }
   ],
   "source": [
    "### 1. 새로운 디렉토리 생성\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "else:\n",
    "    # 디렉토리가 이미 존재하는 경우 예외 처리\n",
    "    shutil.rmtree(DIR)\n",
    "    print(f\"Directory {DIR} already exists. Removing it and creating a new one.\")\n",
    "    os.makedirs(DIR)\n",
    "\n",
    "### 2. checkpoint 및 log, eval_results 디렉토리 복사\n",
    "os.makedirs(os.path.join(DIR, 'checkpoints'), exist_ok=True)\n",
    "os.makedirs(os.path.join(DIR, 'logs'), exist_ok=True)\n",
    "os.makedirs(os.path.join(DIR, 'eval_results'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2385f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "### dir 보기 \n",
    "\"\"\"\n",
    "---DIR1\n",
    "    ---checkpoints\n",
    "    ---eval_results\n",
    "    ---logs (folder+file)\n",
    "\"\"\"\n",
    "### 3. checkpoint 파일 이동\n",
    "def copy_files(init_dir, to_dir):\n",
    "    # checkpoints\n",
    "    init_checkpoint_dir = os.path.join(init_dir, 'checkpoints')\n",
    "    to_checkpoint_dir = os.path.join(to_dir, 'checkpoints')\n",
    "    checkpoints = os.listdir(init_checkpoint_dir) # checkpoint dir의 파일 리스트\n",
    "    for checkpoint in checkpoints:\n",
    "        init_checkpoint_path = os.path.join(init_checkpoint_dir, checkpoint)\n",
    "        to_checkpoint_path = os.path.join(to_checkpoint_dir, checkpoint)\n",
    "        if os.path.isfile(init_checkpoint_path):\n",
    "            shutil.copy2(init_checkpoint_path, to_checkpoint_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{init_checkpoint_path} is not a file.\")\n",
    "    # eval_results\n",
    "    init_eval_results_dir = os.path.join(init_dir, 'eval_results')\n",
    "    to_eval_results_dir = os.path.join(to_dir, 'eval_results')\n",
    "    eval_results = os.listdir(init_eval_results_dir) # eval_results dir의 파일 리스트\n",
    "    for eval_result in eval_results:\n",
    "        init_eval_result_path = os.path.join(init_eval_results_dir, eval_result)\n",
    "        to_eval_result_path = os.path.join(to_eval_results_dir, eval_result)\n",
    "        if os.path.isfile(init_eval_result_path):\n",
    "            shutil.copy2(init_eval_result_path, to_eval_result_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{init_eval_result_path} is not a file.\")\n",
    "    # logs\n",
    "    init_logs_dir = os.path.join(init_dir, 'logs')\n",
    "    to_logs_dir = os.path.join(to_dir, 'logs')\n",
    "    logs = os.listdir(init_logs_dir) # logs dir의 파일 리스트 --> 폴더이다. \n",
    "    for log in logs:\n",
    "        init_log_path = os.path.join(init_logs_dir, log)\n",
    "        to_log_path = os.path.join(to_logs_dir, log)\n",
    "        if os.path.isdir(init_log_path):\n",
    "            shutil.copytree(init_log_path, to_log_path) # copytree는 디렉토리와 그 안의 모든 파일을 복사합니다.\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{init_log_path} is not a directory.\")\n",
    "    return None\n",
    "\n",
    "copy_files(DIR1, DIR)\n",
    "copy_files(DIR2, DIR)\n",
    "print(\"All files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a65d82",
   "metadata": {},
   "source": [
    "### 모델 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f01fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes loaded successfully for len(model_classes): 5\n",
      "Model classes: dict_keys(['SlimDeepCAE_Bottleneck16_Dropout', 'SlimDeepCAE_Bottleneck8_Dropout', 'GANomaly', 'SlimDeepCAE_Bottleneck32_Dropout', 'SlimDeepCAE_Combo'])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import model2, model\n",
    "\n",
    "def get_model_classes():\n",
    "    \"\"\"\n",
    "    model 폴더 내에서 nn.Module 기반 클래스만 자동으로 dict로 반환 (instance가 아니라 class 반환)\n",
    "    \"\"\"\n",
    "    model_classes = {}\n",
    "    for k in dir(model2):\n",
    "        obj = getattr(model2, k)\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj.__module__.startswith('model2.'):\n",
    "            model_classes[k] = obj  # <-- instance() 하지 않고 class 자체만 저장\n",
    "\n",
    "    for k in dir(model):\n",
    "        obj = getattr(model, k)\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj.__module__.startswith('model.'):\n",
    "            model_classes[k] = obj # <-- instance() 하지 않고 class 자체만 저장\n",
    "    return model_classes\n",
    "\n",
    "model_classes = get_model_classes()\n",
    "print(\"Model classes loaded successfully for len(model_classes):\", len(model_classes))\n",
    "print(\"Model classes:\", model_classes.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd3942",
   "metadata": {},
   "source": [
    "### DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8868318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "from torchvision import datasets\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c0bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 6000 Test data size: 3000\n"
     ]
    }
   ],
   "source": [
    "SELECT_NORMAL = 2 # Set 2 class as train dataset.\n",
    "trainset.data = trainset.data[trainset.targets == SELECT_NORMAL]\n",
    "trainset.targets = trainset.targets[trainset.targets == SELECT_NORMAL] # Set 2 class as train dataset.\n",
    "\n",
    "test_label = [2,4,6] # Define actual test class that we use\n",
    "actual_testdata = torch.isin(testset.targets, torch.tensor(test_label))\n",
    "testset.data = testset.data[actual_testdata]\n",
    "testset.targets = testset.targets[actual_testdata]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset, batch_size  = 1,\n",
    "    shuffle     = False,num_workers = 2)\n",
    "\n",
    "train_data_size = len(trainset)\n",
    "test_data_size = len(testset)\n",
    "\n",
    "print(\"Train data size:\", train_data_size, \"Test data size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3eb2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 먼저 train과 val로 나누고, train에 대해서만 증강을 적용\n",
    "n_val = int(len(trainset) * 0.2)\n",
    "n_train = len(trainset) - n_val\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "_, valset = torch.utils.data.random_split(trainset, [n_train, n_val], generator=torch.Generator().manual_seed(2025))\n",
    "# valset은 증강을 적용하지 않음\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = valset, batch_size = 1,\n",
    "    shuffle     = False,num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2d59b",
   "metadata": {},
   "source": [
    "### EVAL ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed84a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class Visualizer:\n",
    "    def __init__(self, test_dataset, test_loader, model, device):\n",
    "        self.test_dataset = test_dataset\n",
    "        self.test_loader = test_loader\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def pick_random_samples(self, num_samples=2):\n",
    "        test_2 = testset.data[testset.targets == 2]\n",
    "        test_4 = testset.data[testset.targets == 4]\n",
    "        test_6 = testset.data[testset.targets == 6]\n",
    "        data_test_2 = test_2.view(test_2.size(0), -1).float() / 255.0\n",
    "        data_test_4 = test_4.view(test_4.size(0), -1).float() / 255.0\n",
    "        data_test_6 = test_6.view(test_6.size(0), -1).float() / 255.0\n",
    "        data_test_2 = data_test_2[:num_samples]\n",
    "        data_test_4 = data_test_4[:num_samples]\n",
    "        data_test_6 = data_test_6[:num_samples]\n",
    "        return [data_test_2, data_test_4, data_test_6]\n",
    "    \n",
    "    def visualize(self, num_samples=2):\n",
    "        data_samples = self.pick_random_samples(num_samples)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        for ax, data_sample, label in zip(axes, data_samples, [2, 4, 6]):\n",
    "            ax.imshow(data_sample[0].view(28, 28).cpu().numpy(), cmap='gray')\n",
    "            ax.set_title(f\"Class {label}\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "    def visualize_reconstruction(self, num_samples=2):\n",
    "        # Reshape the input data to match the expected dimensions for the model\n",
    "        data_samples = self.pick_random_samples(num_samples)\n",
    "        data_samples = [data_sample.view(data_sample.size(0), 1, 28, 28) for data_sample in data_samples]\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "        for ax, data_sample, label in zip(axes, data_samples, [2, 4, 6]):\n",
    "            data_sample = data_sample.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                if hasattr(self.model, 'T'):\n",
    "                    t = torch.randint(0, self.model.T, (data_sample.size(0),), device=self.device)\n",
    "                    output = self.model(data_sample, t) # for diffusion model\n",
    "                else:\n",
    "                    output = self.model(data_sample) # for other models\n",
    "                    if isinstance(output, tuple):\n",
    "                        output = output[0] # for diffusion model\n",
    "            reconstructed = output.view(-1, 28, 28) # Reshape the output to match the image dimensions\n",
    "            reconstructed = reconstructed.cpu()\n",
    "\n",
    "            ax.imshow(reconstructed[0].view(28, 28).numpy(), cmap='gray')\n",
    "            ax.set_title(f\"Class {label} - Reconstructed\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc8f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance(pth_path, model_map:dict, device=None):\n",
    "    \"\"\"\n",
    "    model_name에 해당하는 모델 클래스의 인스턴스를 생성하여 반환\n",
    "    \"\"\"\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1. 파일 이름 추출 (without extension)\n",
    "    filename = os.path.basename(pth_path)  # ex: SlimDeepCAE_Dropout_MSEandMS-SSIMfp16.pth\n",
    "    base_name = filename[:-4]  # remove \".pth\"\n",
    "\n",
    "    # 2. 모델 이름 추출 (Loss/precision 제외한 앞부분)\n",
    "    model_name = base_name.split(\"_\")[:-1] \n",
    "    model_name = \"_\".join(model_name)  # e.g., SlimDeepCAE_Dropout\n",
    "    # if \"_\" in base_name:\n",
    "    #     model_name = \"_\".join(base_name.split(\"_\")[:2])  # e.g., SlimDeepCAE_Dropout\n",
    "\n",
    "    # 3. 모델 클래스 찾기\n",
    "    if model_name not in model_map:\n",
    "        raise ValueError(f\"Unknown model name: {model_name} — 확인된 모델: {list(model_map.keys())}\")\n",
    "\n",
    "    model_class = model_map[model_name]\n",
    "\n",
    "    # 4. 모델 인스턴스 생성 및 weight 로딩\n",
    "    model = model_class().to(device)\n",
    "    state_dict = torch.load(pth_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d31ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.losses import FlexibleLoss\n",
    "\n",
    "reconstruction_loss = {\n",
    "    \"MSE\": FlexibleLoss(mode=\"mse\",reduction=\"none\"),\n",
    "    \"MSE+Gradient\": FlexibleLoss(mode=\"mse+gradient\", beta=1.0, gamma=0.1, reduction=\"none\"),\n",
    "    \"MSE+MS-SSIM\": FlexibleLoss(mode=\"mse+ms-ssim\", beta=1.0, alpha=0.3,reduction=\"none\"),\n",
    "    \"Charbonnier+MS-SSIM\": FlexibleLoss(mode=\"charbonnier+ms-ssim\", beta=1.0, alpha=0.5, reduction=\"none\"),\n",
    "    \"Charbonnier+Gradient\": FlexibleLoss(mode=\"charbonnier+gradient\", beta=1.0, gamma=0.1, reduction=\"none\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_module.grid_loss import GridLossEvaluator\n",
    "import pandas as pd\n",
    "class GridEvaluator:\n",
    "    def __init__(self, val_loader, test_loader, checkpoint_dir, model_map, loss_fns=None, device=None):\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        print(\"Checkpoint directory:\", checkpoint_dir)\n",
    "        self.model_map = model_map\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.visualizer =None\n",
    "        self.loss_fns = loss_fns\n",
    "        self.results = []\n",
    "\n",
    "\n",
    "    def paths(self):\n",
    "        path_list = os.listdir(self.checkpoint_dir) # checkpoint dir의 파일 리스트\n",
    "        path_list = [os.path.join(self.checkpoint_dir, path) for path in path_list if path.endswith('.pth')]\n",
    "        return path_list\n",
    "    \n",
    "    def run(self):\n",
    "        path_list = self.paths()\n",
    "        for path in path_list:\n",
    "            model = get_model_instance(path, self.model_map, self.device)\n",
    "            gridevaluator = GridLossEvaluator(\n",
    "                val_loader=self.val_loader,\n",
    "                test_loader=self.test_loader,\n",
    "                model=model,\n",
    "                loss_fns=self.loss_fns,\n",
    "                device=self.device,\n",
    "                percentile=1.00\n",
    "            )\n",
    "            df = gridevaluator.run()\n",
    "            self.results.append(df)\n",
    "            print(f\"Evaluation completed for {model.__class__.__name__} with path {path}\")\n",
    "\n",
    "    def save_results(self, output_dir='./eval_results'):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        combined_df = pd.concat(self.results, ignore_index=True) # Concatenate all DataFrames into one\n",
    "        combined_df.to_csv(os.path.join(output_dir, 'evaluation_results.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1963b32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory: ./results/latency\\checkpoints\n",
      ">> Using loss: MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 1200/1200 [00:00<00:00, 1312.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 3000/3000 [00:04<00:00, 646.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6249 | PR-AUC: 0.7429 | F1: 0.0020 | ACC: 0.3340\n",
      ">> Using loss: MSE+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 523.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6126 | PR-AUC: 0.7349 | F1: 0.0020 | ACC: 0.3337\n",
      ">> Using loss: MSE+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 554.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 352.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6464 | PR-AUC: 0.7561 | F1: 0.0010 | ACC: 0.3337\n",
      ">> Using loss: Charbonnier+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 575.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 362.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6310 | PR-AUC: 0.7435 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: Charbonnier+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1066.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 517.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5714 | PR-AUC: 0.7033 | F1: 0.0000 | ACC: 0.3333\n",
      "Evaluation completed for SlimDeepCAE_Bottleneck16_Dropout with path ./results/latency\\checkpoints\\SlimDeepCAE_Bottleneck16_Dropout_MSEfp16.pth\n",
      ">> Using loss: MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 1200/1200 [00:00<00:00, 1352.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 3000/3000 [00:05<00:00, 570.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6352 | PR-AUC: 0.7426 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: MSE+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1036.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 516.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6250 | PR-AUC: 0.7368 | F1: 0.0000 | ACC: 0.3330\n",
      ">> Using loss: MSE+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 558.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 358.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6332 | PR-AUC: 0.7476 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: Charbonnier+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 571.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 354.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6225 | PR-AUC: 0.7393 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: Charbonnier+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1043.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 518.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5840 | PR-AUC: 0.7125 | F1: 0.0000 | ACC: 0.3333\n",
      "Evaluation completed for SlimDeepCAE_Bottleneck32_Dropout with path ./results/latency\\checkpoints\\SlimDeepCAE_Bottleneck32_Dropout_MSEfp16.pth\n",
      ">> Using loss: MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 1200/1200 [00:00<00:00, 1302.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 3000/3000 [00:05<00:00, 583.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5665 | PR-AUC: 0.7221 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: MSE+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1046.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 548.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5660 | PR-AUC: 0.7157 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: MSE+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 580.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 358.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6060 | PR-AUC: 0.7679 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: Charbonnier+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 572.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 353.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6114 | PR-AUC: 0.7742 | F1: 0.0000 | ACC: 0.3333\n",
      ">> Using loss: Charbonnier+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 1048.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 505.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5822 | PR-AUC: 0.7309 | F1: 0.0000 | ACC: 0.3333\n",
      "Evaluation completed for SlimDeepCAE_Bottleneck8_Dropout with path ./results/latency\\checkpoints\\SlimDeepCAE_Bottleneck8_Dropout_MSEfp16.pth\n",
      ">> Using loss: MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 1200/1200 [00:00<00:00, 1317.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE): 100%|██████████| 3000/3000 [00:05<00:00, 552.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6462 | PR-AUC: 0.7486 | F1: 0.0010 | ACC: 0.3337\n",
      ">> Using loss: MSE+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 992.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+Gradient): 100%|██████████| 3000/3000 [00:05<00:00, 502.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6376 | PR-AUC: 0.7429 | F1: 0.0010 | ACC: 0.3333\n",
      ">> Using loss: MSE+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 527.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (MSE+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 338.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6400 | PR-AUC: 0.7504 | F1: 0.0010 | ACC: 0.3337\n",
      ">> Using loss: Charbonnier+MS-SSIM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 1200/1200 [00:02<00:00, 534.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+MS-SSIM): 100%|██████████| 3000/3000 [00:08<00:00, 339.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.6304 | PR-AUC: 0.7444 | F1: 0.0010 | ACC: 0.3337\n",
      ">> Using loss: Charbonnier+Gradient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 1200/1200 [00:01<00:00, 989.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring (Charbonnier+Gradient): 100%|██████████| 3000/3000 [00:06<00:00, 495.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROC-AUC: 0.5957 | PR-AUC: 0.7202 | F1: 0.0010 | ACC: 0.3337\n",
      "Evaluation completed for SlimDeepCAE_Combo with path ./results/latency\\checkpoints\\SlimDeepCAE_Combo_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid = GridEvaluator(\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    checkpoint_dir=os.path.join(DIR, 'checkpoints'),\n",
    "    model_map=model_classes,\n",
    "    loss_fns=reconstruction_loss,\n",
    "    device=DEVICE,\n",
    ")\n",
    "grid.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c11e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.save_results(output_dir=os.path.join(DIR, 'eval_results'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
