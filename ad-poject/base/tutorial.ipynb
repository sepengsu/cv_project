{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54103136-928d-423b-bf03-fd5424fdc38c",
   "metadata": {},
   "source": [
    "#### 이상탐지(anomaly detection) 프로젝트\n",
    "#### *Due: 4/29(화) 23:55*\n",
    "\n",
    "## **개요**\n",
    "* 이상탐지는 입력된 샘플을 정상, 비정상 샘플로 구별하는 문제로 의료 분야 및 제조 산업 현장 등에서 사용되고 있습니다. 이번 프로젝트의 목표는 Fashion MNIST(https://github.com/zalandoresearch/fashion-mnist) 데이터로 이상탐지를 수행하여 높은 정확도를 달성하는 것 입니다. 정확도 비교는 kaggle(https://www.kaggle.com/t/127d2f3975314b1ba8558114efe62dce) 에서 진행되며, leaderboard에서 순위 및 정확도를 실시간으로 확인할 수 있습니다. <span style=\"color:red\">해당 kaggle 사이트는 비공개로 링크를 통해서만 접속할 수 있습니다.</span>\n",
    "\n",
    "* 본 프로젝트는 3인/팀으로 수행하는 팀 프로젝트로서 명단은 i-campus에서 확인할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "## **기본코드 제공**\n",
    "* 이상탐지를 수행하는 기본적인 코드를 제공합니다. 해당 코드는 (https://www.kaggle.com/code/yeonghyeon/baseline-uad-w-fashion-mnist-dataset) 를 기반으로 작성되었습니다. Python 및 Pytorch를 활용한 인공지능 모델 설계 경험이 있다면, 본 Tutorial은 무시하셔도 무방합니다. <span style=\"color:red\">하지만, Pytorch를 활용한 인공지능 모델 설계 경험이 없다면 본 Tutorial을 따라가면서 진행하는 것을 추천합니다.</span><br>\n",
    "\n",
    "* 본 튜토리얼 코드를 기반으로 모델을 수정하거나 이전에 제안된 SOTA 이상탐지 방법을 사용해도 좋습니다. 하지만, 코드를 제출할 때 submission form에 맞게 수정하여 제출하여야 합니다.<br>\n",
    "\n",
    "## **제출**\n",
    "\n",
    "* 다음 파일들을 제출합니다: **1**.dataframe(.csv), **2**.모델 코드(.ipynb) + weight(.pt/.pth), **3**.리포트파일, **4**.환경 세팅 목록(.txt), **5**.동료 기여도 평가<br>\n",
    "\n",
    "   **1**.<span style=\"color:blue\">[팀별 제출]</span>-**kaggle에 dataframe(.csv)파일 제출**<br>kaggle에 Fashion MNIST 데이터의 test data를 팀이 구축한 모델에 입력하여 정상/비정상 샘플을 판단한 dataframe파일(.csv)을 제출해야 합니다. <br>dataframe파일(.csv)을 생성하는 방법은 tutorial 하단에 설명되어 있습니다. <span style=\"color:red\">하루에 10번까지 제출할 수 있으며 팀 대표로 1명만 제출해야 합니다.</span><br>\n",
    "\n",
    "   **2**.<span style=\"color:blue\">[팀별 제출]</span>-**i-campus에 모델 코드(.ipynb)및 weight(.pt/.pth) 제출**<br>모델 코드(.ipynb) 와 훈련된 weight(.pt/.pth)를 i-campus에 제출해야 합니다. 모델 코드(.ipynb)는 jupyter notebook 기반으로 생성되야 하며, <span style=\"color:red\">제공되는 submission form에 맞추어서 제출해야 합니다.</span> T.A.가 해당 파일을 실행하여 검토할 예정입니다. 모델 코드(.ipynb)는 본인이 훈련한 모델의 weight(.pt/.pth)를 자동으로 로드하여 훈련없이 실행할 수 있어야 합니다. <span style=\"color:red\">실행 시 오류가 발생할 경우 실행되지 않는 것으로 판단합니다.</span><br>\n",
    "\n",
    "   **3**.<span style=\"color:blue\">[팀별 제출]</span>-**i-campus에 리포트 제출**<br>리포트는 i-campus에 제출해야 합니다. 리포트는 IEEE Conference style(two column format)을 사용하여 2페이지 이내로 작성해야 하며 네트워크에 대한 설명, AUROC 그래프 등이 포함되어야 합니다. 예를 들면, 해당 네트워크로 설계한 이유 혹은 다른 SOTA 방법을 활용하였다면, 인용문구와 함께 네트워크 어느 부분이 정확도 개선에 기여하는지에 대해서 기술해야 합니다.\n",
    "\n",
    "   **4**.<span style=\"color:blue\">[팀별 제출]</span>-**<span style=\"color:red\">(해당하는 팀만 제출)</span> i-campus에 환경 세팅 목록 제출**<br>이전에 제안된 이상탐지 모델 방법을 활용하였다면, 환경 세팅 목록을(requirement.txt) 제출해야 합니다.\n",
    "\n",
    "   **5**.<span style=\"color:green\">[개인별 제출]</span>-**i-campus에 동료 기여도 평가지 제출**<br>동료 기여도 평가는 제공되는 양식에 작성하여 i-campus에 <span style=\"color:green\">개인별로</span> 제출하셔야 합니다.<br>\n",
    "   <br>\n",
    "* 모든 제출 파일의 <span style=\"color:red\">due는 4/29(화) 23:55</span> 까지입니다.\n",
    "\n",
    "\n",
    "\n",
    "## **점수 반영(subject to change)**\n",
    "* Kaggle 리더보드 등수 - 70% <br>\n",
    "* 리포트(모델 코드 포함) - 30% <br>\n",
    "\n",
    "\n",
    "\n",
    "## **주의사항**\n",
    "\n",
    "* 다른 SOTA 방법을 활용 했다면, 명시를 해야 합니다. 인용을 하지 않은 경우 문제가 될 수 있습니다.<br>\n",
    "\n",
    "* 다른 SOTA 방법을 활용 했다면, 코드를 submission form에 맞추어서 직접 수정 및 훈련해야 합니다. github에 공유되어 있는 코드 파일들과 사전훈련된 weight를 그대로 제출하는 것은 허용되지 않습니다. <br>\n",
    "\n",
    "* 다른 팀의 코드를 재사용 하는 것은 불가합니다. <br>\n",
    "\n",
    "* 비정상적으로 네트워크의 정확도를 개선하는 경우는(e. g., test data를 훈련에 사용, dataframe(.csv) 파일을 수동으로 변경하여 제출 등) 0점 처리 합니다. <br>\n",
    "\n",
    "* 리포트에 사용한 AUROC 그래프와 코드로 생성된 AUROC가 다를 경우 문제가 될 수 있습니다. <br>\n",
    "\n",
    "\n",
    "## **문의**\n",
    "* 팀 프로젝트를 수행중 발생하는 문의 사항은 T.A.에게 문의를 주시면 됩니다.<br>\n",
    "\n",
    "컴퓨터비전 연구실(산학협력센터 85745)<br>\n",
    "박현규 T.A.<br>\n",
    "mjss016@skku.edu<br>\n",
    "\n",
    "i-campus 쪽지가 아닌 이메일로 문의를 부탁합니다. <br> 기본적으로 모든 질문에 대해서 답변을 제공할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4effd3-2f34-4906-b581-e7e066aebede",
   "metadata": {},
   "source": [
    "# **Brief tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720c169-3ad0-4d1d-93a1-ac4584f35205",
   "metadata": {},
   "source": [
    "#### **이상탐지(anomaly detection)**\n",
    "본 tutorial은 reconstruction-based anomaly detection을 기반으로 합니다.<br>\n",
    "![ad](example/ad_train.png)<br>\n",
    "일반적으로 Reconstruction-based anomaly detection은 정상 샘플만을 이용하여 오토인코더를 학습시킵니다.<br>\n",
    "![ad](example/ad_test.png)<br>\n",
    "\n",
    "이론상 학습된 오토인코더는 훈련 과정에서 정상 샘플만 활용했기 때문에 정상 샘플이 입력되면 정상 샘플로 복원을 할 수 있지만, 훈련 과정에서 사용하지 않은 비정상 샘플이 입력되면 비정상 샘플로 복원을 할 수 없습니다. <br>\n",
    "![ad](example/ad_vis.png)<br>\n",
    "\n",
    "\n",
    "이를 활용하여 입력되는 샘플과 출력되는 샘플의 reconstruction error를 측정하여 정상 샘플과 비정상 샘플을 구별할 수 있습니다.\n",
    "\n",
    "\n",
    "하지만, <span style=\"color:red\">오토인코더는 일반화 성능(generalization ability)이 우수하여 훈련과정에서 활용하지 않은 비정상 샘플이 입력되도 비정상 샘플로 잘 복원하는 문제점이 발생합니다.</span> 따라서 네트워크를 설계할 때 **일반화 성능을 억제하여 정상 샘플은 잘 복원하되 비정상 샘플은 복원하지 못하도록 설계**하는 것이 중요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b1736-e56e-4bb8-beec-9639c5d18218",
   "metadata": {},
   "source": [
    "#### **데이터셋**\n",
    "Anomaly detection에서 사용되는 다양한 데이터셋이 있지만, 수강생들의 서버 보유 여부를 고려하여 Fashion MNIST(https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 활용합니다. Fashion MNIST는 28x28 사이즈의 회색조 이미지며 아래의 표와 같이 **0-9**까지의 레이블이 존재합니다.  훈련 데이터셋은 **0-9**번 레이블 6만장으로 테스트 데이터셋은 0-9번 레이블 1만장으로 이루어져있습니다.<br>\n",
    "![fashion](example/fashion.png)\n",
    "<span style=\"color:red\">2번 레이블(Pullover)을 정상 샘플</span>로서 , <span style=\"color:red\">4, 6번 레이블은 비정상 샘플</span>로 활용해야 합니다. 네트워크를 훈련할 때 반드시 train 데이터셋의 2번 label만 활용해야 합니다.<br>\n",
    "\n",
    "![fashion_label](example/fashion_label.png)<br>\n",
    "따라서, **Fashion MNIST의 훈련 데이터셋에서 2번(Pullover) label만 훈련에 활용**해야 하며, **Fashion MNIST의 테스트 데이터셋에서 2(Pullover), 4(Coat), 6번(Shirt) label만 활용**해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8b0cc-dc91-4635-8cb5-52e58662c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call library\n",
    "# kaggle 기준 해당 .ipynb파일이 작동하는 것을 확인했습니다. 만약, 로컬환경에서 실행할 예정이라면, 아래 링크를 활용해서 설치해주세요.\n",
    "# https://pytorch.org/get-started/previous-versions/\n",
    "# 로컬에서 테스트된 환경은 다음과 같습니다. pytorch 2.0.0 with python=3.9, cuda=11.7, cudnn=8.0, torchvision==0.15.0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d106579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter setting\n",
    "# https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "# Computational device\n",
    "# Device will be set to GPU if it is available.(you should install valid Pytorch version with CUDA. Otherwise, it will be computed using CPU)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "# dataset detail\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential( \n",
    "            nn.Linear(28*28, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid(), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x) \n",
    "        decoded = self.decoder(encoded) \n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set for data loader\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "SELECT_NORMAL = 2 # Set 2 class as train dataset.\n",
    "trainset.data = trainset.data[trainset.targets == SELECT_NORMAL]\n",
    "trainset.targets = trainset.targets[trainset.targets == SELECT_NORMAL]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "test_label = [2,4,6] # Define actual test class that we use\n",
    "actual_testdata = torch.isin(testset.targets, torch.tensor(test_label))\n",
    "testset.data = testset.data[actual_testdata]\n",
    "testset.targets = testset.targets[actual_testdata]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset,\n",
    "    batch_size  = 1,\n",
    "    shuffle     = False,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize training procedure\n",
    "view_data = []\n",
    "for i in test_label:\n",
    "    view_data.append(testset.data[testset.targets == i][0].view(28*28))\n",
    "view_data = torch.Tensor(np.array(view_data))\n",
    "view_data = view_data.type(torch.FloatTensor)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47320294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of autoencoder and loss function\n",
    "# https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "autoencoder = Autoencoder().to(DEVICE) # generating instance of model that you build.\n",
    "print(autoencoder) # you can check your model \n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LEARNING_RATE) # if you want to utilie other optimizer, replace Adam to other.\n",
    "criterion = nn.MSELoss() # you can change loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "# https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "def train(autoencoder, train_loader):\n",
    "    autoencoder.train()\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        x = x.view(-1, 28*28).to(DEVICE)\n",
    "        y = x.view(-1, 28*28).to(DEVICE) \n",
    "\n",
    "        encoded, decoded = autoencoder(x)\n",
    "\n",
    "        loss = criterion(decoded, y) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process including visualization\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    train(autoencoder, train_loader)\n",
    "\n",
    "    test_x = view_data.to(DEVICE)\n",
    "    _, decoded_data = autoencoder(test_x)\n",
    "\n",
    "    f, a = plt.subplots(2, len(test_label), figsize=(len(test_label), 2))\n",
    "    print(\"[Epoch {}]\".format(epoch))\n",
    "    for i in range(len(test_label)):\n",
    "        img = np.reshape(view_data.data.numpy()[i],(28, 28)) \n",
    "        a[0][i].imshow(img, cmap='gray')\n",
    "        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "        if(i == 0): a[0][i].set_ylabel('Input')\n",
    "\n",
    "    for i in range(len(test_label)):\n",
    "        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28)) \n",
    "        a[1][i].imshow(img, cmap='gray')\n",
    "        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "        if(i == 0): a[1][i].set_ylabel('Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "THRESHOLDVAL=0.01 # threshold val\n",
    "dic_loss = {'id':[], 'label':[], 'score':[],'normal':[]}\n",
    "\n",
    "count=0\n",
    "for step, (x, label) in enumerate(test_loader):\n",
    "    x = x.view(-1, 28*28).to(DEVICE)\n",
    "    y = x.view(-1, 28*28).to(DEVICE) \n",
    "\n",
    "    encoded, decoded = autoencoder(x)\n",
    "    loss = float(criterion(decoded, y).cpu().detach().numpy())\n",
    "    dic_loss['id'].append(step)\n",
    "    dic_loss['label'].append(int(label==SELECT_NORMAL)) # 1: normal, 0: abnormal\n",
    "    dic_loss['score'].append(loss) # abnormal score\n",
    "    if loss>THRESHOLDVAL: dic_loss['normal'].append('0')\n",
    "    else: dic_loss['normal'].append('1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c634e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gernerating a plot\n",
    "arr_label = np.array(dic_loss['label'])\n",
    "arr_score = np.array(dic_loss['score'])\n",
    "score_min = arr_score.min()\n",
    "score_max = arr_score.max()\n",
    "plt.hist(arr_score[np.where(arr_label == 1)[0]], bins=30, range=(score_min, score_max), alpha=0.5, label='Normal')\n",
    "plt.hist(arr_score[np.where(arr_label == 0)[0]], bins=30, range=(score_min, score_max), alpha=0.5, label='Abnormal')\n",
    "plt.xlabel(\"Anomaly score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(THRESHOLDVAL,0,1, color='red',linestyle='--',linewidth=1)\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating AUROC\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
    "fpr, tpr, thresholds = roc_curve(dic_loss['label'], dic_loss['score'], pos_label=0)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.savefig(\"auroc.png\")\n",
    "plt.show()\n",
    "auroc = auc(fpr, tpr)\n",
    "print(\"AUROC: {}\".format(auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e971b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leveraging the pandas library to convert a dict to a dataframe is more convenient when checking values.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "df = pd.DataFrame.from_dict(dic_loss)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a46acf-7944-4bf9-9a04-c911c3973fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to submit .csv file to kaggle, dataframe should fit following format\n",
    "# id[1,2,3...,3000], predicted anomalies[0,1,0....,0]\n",
    "\n",
    "# 'pop('score,None')' delete one of the item in dict\n",
    "# 'del df['item']', is also available.\n",
    "\n",
    "# If you try to remove invalid itmes in the dict, message that you set will be returned.\n",
    "# set to None, nothing will be returned\n",
    "dic_loss.pop('score',None)\n",
    "dic_loss.pop('label',None)\n",
    "df = pd.DataFrame.from_dict(dic_loss)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12310bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_csv command will convert your dict to .csv file with the name of your teamnumber\n",
    "# Do not forget to submit the .csv file to kaggle. If you upload .csv file properly to kaggle, you can check your result immediately at the leaderboard.\n",
    "teamnumber = 1 # insert your teamnumber\n",
    "df.to_csv(\"result_team{}.csv\".format(teamnumber), index =False) # Index should be not included in the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24485430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "# you can save your weight.\n",
    "torch.save(autoencoder.state_dict(), 'model_team{}.pth'.format(teamnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75b5fd-a762-47a4-95c4-198e96363d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
