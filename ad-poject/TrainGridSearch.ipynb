{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import copy, os\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Computational device\n",
    "# Device will be set to GPU if it is available.(you should install valid Pytorch version with CUDA. Otherwise, it will be computed using CPU)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "DIR = './results/gridsearch16'\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 6000 Test data size: 3000\n"
     ]
    }
   ],
   "source": [
    "SELECT_NORMAL = 2 # Set 2 class as train dataset.\n",
    "trainset.data = trainset.data[trainset.targets == SELECT_NORMAL]\n",
    "trainset.targets = trainset.targets[trainset.targets == SELECT_NORMAL] # Set 2 class as train dataset.\n",
    "\n",
    "test_label = [2,4,6] # Define actual test class that we use\n",
    "actual_testdata = torch.isin(testset.targets, torch.tensor(test_label))\n",
    "testset.data = testset.data[actual_testdata]\n",
    "testset.targets = testset.targets[actual_testdata]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset, batch_size  = 1,\n",
    "    shuffle     = False,num_workers = 2)\n",
    "\n",
    "train_data_size = len(trainset)\n",
    "test_data_size = len(testset)\n",
    "\n",
    "print(\"Train data size:\", train_data_size, \"Test data size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 증강 기법 사용 class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.1):\n",
    "        super().__init__()\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = x.data.new(x.size()).normal_(0, self.std)\n",
    "            return x + noise\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 배로 Augmentation을 할 것인지 알려주면 해당 배수만큼 Augmentation을 수행하는 클래스\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),                  # 20도는 좀 크고, 15도 이하 권장\n",
    "    transforms.RandomCrop(28, padding=2),           # shift 효과\n",
    "    GaussianNoise(0.1),                          # Gaussian Noise 추가  \n",
    "])\n",
    "\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None, augmentation_factor=1):\n",
    "        '''\n",
    "        dataset: 원본 데이터셋\n",
    "        transform: 증강을 위한 transform\n",
    "        augmentation_factor: 몇 배로 Augmentation (1 포함)\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.augmentation_factor = augmentation_factor\n",
    "        self.original_length = len(dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 전체 데이터 수 = 원본 * 배수\n",
    "        return self.original_length * self.augmentation_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 원본 인덱스\n",
    "        original_idx = idx % self.original_length\n",
    "        x, y = self.dataset[original_idx]\n",
    "\n",
    "        # factor == 1 이거나 첫 번째 패스는 원본 사용\n",
    "        if self.augmentation_factor > 1 and idx >= self.original_length:\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 24000 Val data size: 1200 Test data size: 3000\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 먼저 train과 val로 나누고, train에 대해서만 증강을 적용\n",
    "n_val = int(len(trainset) * 0.2)\n",
    "n_train = len(trainset) - n_val\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "augset, valset = torch.utils.data.random_split(trainset, [n_train, n_val], generator=torch.Generator().manual_seed(2025))\n",
    "\n",
    "augset = AugmentedDataset(augset, transform=transform, augmentation_factor=5) # augmentation_factor = 5 for baseline 모델 찾기 \n",
    "# valset은 증강을 적용하지 않음\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = augset, batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,num_workers = 0) \n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = valset, batch_size = BATCH_SIZE,\n",
    "    shuffle     = False,num_workers = 0)\n",
    "\n",
    "# data size check\n",
    "print(\"Train data size:\", len(augset),\"Val data size:\", len(valset),\"Test data size:\", len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 및 Training Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        '''\n",
    "        patience (int): 얼마나 기다릴지\n",
    "        verbose (bool): True일 경우 각 epoch의 loss 출력\n",
    "        delta (float): 개선이 되었다고 인정되는 최소한의 loss\n",
    "        '''\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss # validation loss가 작을수록 좋다고 가정\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 및 loss 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: dict_keys(['Autoencoder', 'CAE', 'CVAE', 'DeepCAE', 'DeepCVAE', 'DeepVAE', 'DenoisingAutoencoder', 'DiffusionUNet', 'GANomaly', 'HybridCAE', 'RobustAutoencoder', 'SimpleDDPM', 'SkipConnectionAutoencoder', 'TransformerAnomalyDetector', 'VAE'])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import model\n",
    "\n",
    "def get_model_classes():\n",
    "    \"\"\"\n",
    "    model 폴더 내에서 nn.Module 기반 클래스만 자동으로 dict로 반환 (instance가 아니라 class 반환)\n",
    "    \"\"\"\n",
    "    model_classes = {}\n",
    "    for k in dir(model):\n",
    "        obj = getattr(model, k)\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj.__module__.startswith('model.'):\n",
    "            model_classes[k] = obj  # <-- instance() 하지 않고 class 자체만 저장\n",
    "    return model_classes\n",
    "\n",
    "# 이제 model_classes는 {name: class} 형태로만 보관\n",
    "model_classes = get_model_classes()\n",
    "print(\"Available models:\", model_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available reconstruction loss functions: dict_keys(['MSE', 'MSE+Gradient', 'MSE+MS-SSIM', 'Charbonnier+MS-SSIM', 'Charbonnier+Gradient'])\n",
      "Available diffusion loss functions: dict_keys(['MSE', 'MSE+Gradient', 'Charbonnier', 'Charbonnier+Gradient'])\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "# loss function 추천 조합\n",
    "from loss.losses import FlexibleLoss, FlexibleDiffusionLoss\n",
    "\n",
    "reconstruction_loss = {\n",
    "    \"MSE\": FlexibleLoss(mode=\"mse\"),\n",
    "    \"MSE+Gradient\": FlexibleLoss(mode=\"mse+gradient\", beta=1.0, gamma=0.1),\n",
    "    \"MSE+MS-SSIM\": FlexibleLoss(mode=\"mse+ms-ssim\", beta=1.0, alpha=0.3),\n",
    "    \"Charbonnier+MS-SSIM\": FlexibleLoss(mode=\"charbonnier+ms-ssim\", beta=1.0, alpha=0.5),\n",
    "    \"Charbonnier+Gradient\": FlexibleLoss(mode=\"charbonnier+gradient\", beta=1.0, gamma=0.1),\n",
    "}\n",
    "\n",
    "diffusion_loss = {\n",
    "    \"MSE\": FlexibleDiffusionLoss(mode=\"mse\"),\n",
    "    \"MSE+Gradient\": FlexibleDiffusionLoss(mode=\"mse+gradient\", beta=1.0, alpha=0.1),\n",
    "    \"Charbonnier\": FlexibleDiffusionLoss(mode=\"charbonnier\", beta=1.0),\n",
    "    \"Charbonnier+Gradient\": FlexibleDiffusionLoss(mode=\"charbonnier+gradient\", beta=1.0, alpha=0.1)\n",
    "}\n",
    "loss_functions = {\n",
    "    \"reconstruction\": reconstruction_loss,\n",
    "    \"diffusion\": diffusion_loss,\n",
    "}\n",
    "\n",
    "print(\"Available reconstruction loss functions:\", reconstruction_loss.keys())\n",
    "print(\"Available diffusion loss functions:\", diffusion_loss.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Autoencoder has missing checkpoints. Keeping in list.\n",
      "❌ CAE has missing checkpoints. Keeping in list.\n",
      "❌ CVAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepCAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepCVAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepVAE has missing checkpoints. Keeping in list.\n",
      "❌ DenoisingAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ DiffusionUNet has missing checkpoints. Keeping in list.\n",
      "❌ GANomaly has missing checkpoints. Keeping in list.\n",
      "❌ HybridCAE has missing checkpoints. Keeping in list.\n",
      "❌ RobustAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ SimpleDDPM has missing checkpoints. Keeping in list.\n",
      "❌ SkipConnectionAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ TransformerAnomalyDetector has missing checkpoints. Keeping in list.\n",
      "❌ VAE has missing checkpoints. Keeping in list.\n",
      "Remaining models: dict_keys(['Autoencoder', 'CAE', 'CVAE', 'DeepCAE', 'DeepCVAE', 'DeepVAE', 'DenoisingAutoencoder', 'DiffusionUNet', 'GANomaly', 'HybridCAE', 'RobustAutoencoder', 'SimpleDDPM', 'SkipConnectionAutoencoder', 'TransformerAnomalyDetector', 'VAE'])\n"
     ]
    }
   ],
   "source": [
    "def model_delete(models, loss_functions, checkpoint_dir):\n",
    "    '''\n",
    "    이미 학습된 모델 + loss 조합을 models, loss_functions에서 제거\n",
    "    checkpoint_dir/{model_name}_{loss_name}.pth 존재 여부로 판단\n",
    "    '''\n",
    "    models_to_delete = []\n",
    "\n",
    "    for model_name in list(models.keys()):\n",
    "        # 현재 모델이 사용 가능한 loss 목록\n",
    "        if hasattr(models[model_name], 'T'):\n",
    "            losses = list(loss_functions['diffusion'].keys())\n",
    "        else:\n",
    "            losses = list(loss_functions['reconstruction'].keys())\n",
    "        \n",
    "        # 해당 모델의 모든 loss 조합이 학습되었는지 확인\n",
    "        all_ckpt_exist = all(\n",
    "            os.path.exists(os.path.join(checkpoint_dir, f\"{model_name}_{loss.replace('+','and')}.pth\"))\n",
    "            for loss in losses\n",
    "        )\n",
    "\n",
    "        if all_ckpt_exist:\n",
    "            print(f\"✅ {model_name} all checkpoints exist. Removing from list.\")\n",
    "            models_to_delete.append(model_name)\n",
    "        else:\n",
    "            print(f\"❌ {model_name} has missing checkpoints. Keeping in list.\")\n",
    "    \n",
    "    # 실제 삭제\n",
    "    for model_name in models_to_delete:\n",
    "        del models[model_name]\n",
    "\n",
    "    return models\n",
    "# 모델과 loss function 조합을 삭제\n",
    "model_classes = model_delete(model_classes, loss_functions, DIR)\n",
    "print(\"Remaining models:\", model_classes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch image shape: torch.Size([1024, 1, 28, 28])\n",
      "Train batch label shape: torch.Size([1024])\n",
      "Test batch image shape: torch.Size([1, 1, 28, 28])\n",
      "Test batch label shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of a batch from train_loader and test_loader\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "print(\"Train batch image shape:\", train_images.shape)\n",
    "print(\"Train batch label shape:\", train_labels.shape)\n",
    "print(\"Test batch image shape:\", test_images.shape)\n",
    "print(\"Test batch label shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Total Models: 15\n",
      "Reconstruction Losses: 5 Diffusion Losses: 4\n",
      "Total Combinations: 74\n",
      "==================================================\n",
      "▶ Training [Autoencoder] with [MSE] (FP16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Autoencoder | MSE (FP16):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "PATIENCE = 20\n",
    "# GridSearchTrainerfp16\n",
    "from trainer import GridSearchTrainerFP16, GridSearchTrainer\n",
    "trainer = GridSearchTrainerFP16(\n",
    "    models=model_classes,\n",
    "    criterions_dict=loss_functions,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    save_dir=f'{DIR}/checkpoints',\n",
    "    verbose=False, \n",
    "    device=DEVICE,\n",
    "    lr=1e-3 * BATCH_SIZE / 256, # default learning rate for AdamW\n",
    "    log_dir=f'{DIR}/logs/1',\n",
    ")\n",
    "results = trainer.run()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(f'{DIR}/training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>save_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.054278</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/Autoencoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>MSE+Gradient</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/Autoencoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>MSE+MS-SSIM</td>\n",
       "      <td>0.186224</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/Autoencoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>Charbonnier+MS-SSIM</td>\n",
       "      <td>0.374743</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/Autoencoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>Charbonnier+Gradient</td>\n",
       "      <td>0.185898</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/Autoencoder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>VAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/VAE_MSEfp16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>VAE</td>\n",
       "      <td>MSE+Gradient</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/VAE_MSEandG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>VAE</td>\n",
       "      <td>MSE+MS-SSIM</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/VAE_MSEandM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>VAE</td>\n",
       "      <td>Charbonnier+MS-SSIM</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/VAE_Charbon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>VAE</td>\n",
       "      <td>Charbonnier+Gradient</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>1</td>\n",
       "      <td>./results/gridsearch16/checkpoints/VAE_Charbon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                  loss  best_val_loss  best_epoch  \\\n",
       "0   Autoencoder                   MSE       0.054278           1   \n",
       "1   Autoencoder          MSE+Gradient       0.076400           1   \n",
       "2   Autoencoder           MSE+MS-SSIM       0.186224           1   \n",
       "3   Autoencoder   Charbonnier+MS-SSIM       0.374743           1   \n",
       "4   Autoencoder  Charbonnier+Gradient       0.185898           1   \n",
       "..          ...                   ...            ...         ...   \n",
       "69          VAE                   MSE       0.005543           1   \n",
       "70          VAE          MSE+Gradient       0.006277           1   \n",
       "71          VAE           MSE+MS-SSIM       0.004484           1   \n",
       "72          VAE   Charbonnier+MS-SSIM       0.009215           1   \n",
       "73          VAE  Charbonnier+Gradient       0.006838           1   \n",
       "\n",
       "                                            save_path  \n",
       "0   ./results/gridsearch16/checkpoints/Autoencoder...  \n",
       "1   ./results/gridsearch16/checkpoints/Autoencoder...  \n",
       "2   ./results/gridsearch16/checkpoints/Autoencoder...  \n",
       "3   ./results/gridsearch16/checkpoints/Autoencoder...  \n",
       "4   ./results/gridsearch16/checkpoints/Autoencoder...  \n",
       "..                                                ...  \n",
       "69  ./results/gridsearch16/checkpoints/VAE_MSEfp16...  \n",
       "70  ./results/gridsearch16/checkpoints/VAE_MSEandG...  \n",
       "71  ./results/gridsearch16/checkpoints/VAE_MSEandM...  \n",
       "72  ./results/gridsearch16/checkpoints/VAE_Charbon...  \n",
       "73  ./results/gridsearch16/checkpoints/VAE_Charbon...  \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir {DIR}/logs/1 --host localhost --port 6006 --bind_all &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, checkpoint_dir, val_loader, test_loader, device=None, percentile=0.95, save_dir='./eval_results'):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.percentile = percentile\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"모델 이름으로부터 instance 생성\"\"\"\n",
    "        model_class = get_model_classes()[model_name]\n",
    "        model = model_class().to(self.device)\n",
    "        return model\n",
    "\n",
    "    def compute_score(self, model, x):\n",
    "        \"\"\"Diffusion → noise mse / AE, VAE, etc → recon mse\"\"\"\n",
    "        if hasattr(model, 'T'):\n",
    "            t = torch.randint(0, model.T, (x.size(0),), device=x.device)\n",
    "            noise_pred, noise = model(x, t)\n",
    "            return F.mse_loss(noise_pred, noise, reduction='none').view(x.size(0), -1).mean(dim=1)\n",
    "        else:\n",
    "            output = model(x)\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]\n",
    "            return F.mse_loss(output, x, reduction='none').view(x.size(0), -1).mean(dim=1)\n",
    "\n",
    "    def get_scores(self, loader, model):\n",
    "        \"\"\"Validation 또는 Test set에 대한 score 계산\"\"\"\n",
    "        model.eval()\n",
    "        scores, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(loader, desc=\"Scoring\"):\n",
    "                x = x.to(self.device)\n",
    "                score = self.compute_score(model, x)\n",
    "                scores.append(score.cpu())\n",
    "                labels.append(y.cpu())\n",
    "        return torch.cat(scores).numpy(), torch.cat(labels).numpy()\n",
    "\n",
    "    def run(self):\n",
    "        checkpoint_files = [f for f in os.listdir(self.checkpoint_dir) if f.endswith(\".pth\")]\n",
    "        results = []\n",
    "\n",
    "        for ckpt in checkpoint_files:\n",
    "            print(f\"\\n▶ Evaluating {ckpt}\")\n",
    "\n",
    "            # 안전하게 loss_name에 _가 여러 개 들어가도 마지막만 split\n",
    "            model_name, loss_name = ckpt[:-4].rsplit(\"_\", 1)\n",
    "\n",
    "            model = self.load_model(model_name)\n",
    "            model.load_state_dict(torch.load(os.path.join(self.checkpoint_dir, ckpt)))\n",
    "\n",
    "            # --------------------------\n",
    "            # Threshold 계산 (Validation)\n",
    "            # --------------------------\n",
    "            val_scores, _ = self.get_scores(self.val_loader, model)\n",
    "            threshold = np.percentile(val_scores, self.percentile * 100)\n",
    "            print(f\" >> Threshold ({self.percentile*100:.0f}%) = {threshold:.4f}\")\n",
    "\n",
    "            # --------------------------\n",
    "            # Test 평가\n",
    "            # --------------------------\n",
    "            test_scores, test_labels = self.get_scores(self.test_loader, model)\n",
    "            test_labels = (test_labels != 2).astype(int)  # class 2 = normal\n",
    "            preds = (test_scores > threshold).astype(int)\n",
    "\n",
    "            auc_score = roc_auc_score(test_labels, test_scores)\n",
    "            precision, recall, _ = precision_recall_curve(test_labels, test_scores)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            f1 = f1_score(test_labels, preds)\n",
    "            acc = accuracy_score(test_labels, preds)\n",
    "\n",
    "            print(f\"ROC-AUC: {auc_score:.4f} | PR-AUC: {pr_auc:.4f} | F1: {f1:.4f} | ACC: {acc:.4f}\")\n",
    "\n",
    "            results.append({\n",
    "                \"checkpoint\": ckpt,\n",
    "                \"threshold\": threshold,\n",
    "                \"roc_auc\": auc_score,\n",
    "                \"pr_auc\": pr_auc,\n",
    "                \"f1\": f1,\n",
    "                \"acc\": acc\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Evaluating Autoencoder_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 41.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 696.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5138 | PR-AUC: 0.6652 | F1: 0.0466 | ACC: 0.3320\n",
      "\n",
      "▶ Evaluating Autoencoder_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 42.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 719.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5356 | PR-AUC: 0.6870 | F1: 0.0737 | ACC: 0.3463\n",
      "\n",
      "▶ Evaluating Autoencoder_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 40.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 712.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5260 | PR-AUC: 0.6780 | F1: 0.0761 | ACC: 0.3443\n",
      "\n",
      "▶ Evaluating Autoencoder_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 42.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 722.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5316 | PR-AUC: 0.6898 | F1: 0.0783 | ACC: 0.3490\n",
      "\n",
      "▶ Evaluating Autoencoder_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 43.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 724.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5248 | PR-AUC: 0.6808 | F1: 0.0913 | ACC: 0.3497\n",
      "\n",
      "▶ Evaluating CAE_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 650.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.3801 | PR-AUC: 0.5837 | F1: 0.0428 | ACC: 0.3290\n",
      "\n",
      "▶ Evaluating CAE_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 612.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4113 | PR-AUC: 0.6185 | F1: 0.0855 | ACC: 0.3440\n",
      "\n",
      "▶ Evaluating CAE_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 627.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.3516 | PR-AUC: 0.5783 | F1: 0.0604 | ACC: 0.3363\n",
      "\n",
      "▶ Evaluating CAE_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 639.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4034 | PR-AUC: 0.6205 | F1: 0.1125 | ACC: 0.3533\n",
      "\n",
      "▶ Evaluating CAE_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 654.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.3779 | PR-AUC: 0.5924 | F1: 0.0694 | ACC: 0.3380\n",
      "\n",
      "▶ Evaluating CVAE_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 590.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4512 | PR-AUC: 0.6174 | F1: 0.0251 | ACC: 0.3277\n",
      "\n",
      "▶ Evaluating CVAE_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 613.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4533 | PR-AUC: 0.6431 | F1: 0.0800 | ACC: 0.3483\n",
      "\n",
      "▶ Evaluating CVAE_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 602.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4899 | PR-AUC: 0.6523 | F1: 0.0656 | ACC: 0.3443\n",
      "\n",
      "▶ Evaluating CVAE_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 606.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4828 | PR-AUC: 0.6529 | F1: 0.0647 | ACC: 0.3443\n",
      "\n",
      "▶ Evaluating CVAE_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 613.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4737 | PR-AUC: 0.6387 | F1: 0.0487 | ACC: 0.3360\n",
      "\n",
      "▶ Evaluating DeepCAE_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 643.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4343 | PR-AUC: 0.6143 | F1: 0.0382 | ACC: 0.3293\n",
      "\n",
      "▶ Evaluating DeepCAE_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 625.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4502 | PR-AUC: 0.6136 | F1: 0.0383 | ACC: 0.3300\n",
      "\n",
      "▶ Evaluating DeepCAE_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 27.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 608.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5094 | PR-AUC: 0.6459 | F1: 0.0309 | ACC: 0.3307\n",
      "\n",
      "▶ Evaluating DeepCAE_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 27.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 562.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4586 | PR-AUC: 0.6266 | F1: 0.0585 | ACC: 0.3350\n",
      "\n",
      "▶ Evaluating DeepCAE_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 607.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4386 | PR-AUC: 0.6104 | F1: 0.0401 | ACC: 0.3303\n",
      "\n",
      "▶ Evaluating DeepCVAE_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 526.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4938 | PR-AUC: 0.6620 | F1: 0.0666 | ACC: 0.3460\n",
      "\n",
      "▶ Evaluating DeepCVAE_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 25.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 520.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4977 | PR-AUC: 0.6818 | F1: 0.0984 | ACC: 0.3583\n",
      "\n",
      "▶ Evaluating DeepCVAE_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 26.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 502.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5592 | PR-AUC: 0.6850 | F1: 0.0544 | ACC: 0.3397\n",
      "\n",
      "▶ Evaluating DeepCVAE_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 525.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5174 | PR-AUC: 0.6740 | F1: 0.0774 | ACC: 0.3487\n",
      "\n",
      "▶ Evaluating DeepCVAE_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 26.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 571.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5271 | PR-AUC: 0.6704 | F1: 0.0489 | ACC: 0.3393\n",
      "\n",
      "▶ Evaluating DeepVAE_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 43.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 603.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4684 | PR-AUC: 0.6434 | F1: 0.0638 | ACC: 0.3447\n",
      "\n",
      "▶ Evaluating DeepVAE_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 670.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5126 | PR-AUC: 0.6705 | F1: 0.0674 | ACC: 0.3447\n",
      "\n",
      "▶ Evaluating DeepVAE_MSEandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 44.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 613.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5134 | PR-AUC: 0.6671 | F1: 0.0601 | ACC: 0.3427\n",
      "\n",
      "▶ Evaluating DeepVAE_MSEandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 40.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 581.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5129 | PR-AUC: 0.6728 | F1: 0.0676 | ACC: 0.3467\n",
      "\n",
      "▶ Evaluating DeepVAE_MSEfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 595.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5004 | PR-AUC: 0.6615 | F1: 0.0657 | ACC: 0.3453\n",
      "\n",
      "▶ Evaluating DenoisingAutoencoder_CharbonnierandGradientfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (95%) = 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 629.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.3732 | PR-AUC: 0.5846 | F1: 0.0558 | ACC: 0.3347\n",
      "\n",
      "▶ Evaluating DenoisingAutoencoder_CharbonnierandMS-SSIMfp16.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(\n",
    "    checkpoint_dir=f'{DIR}/checkpoints',\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=DEVICE,\n",
    "    percentile=0.95,\n",
    "    save_dir=f'{DIR}/eval_results'  # ⭕ 저장할 디렉토리\n",
    ")\n",
    "eval_results = evaluator.run()\n",
    "eval_results.to_csv(f'{DIR}/eval_results/eval_results.csv', index=False)  # ⭕ CSV로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
