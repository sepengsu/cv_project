{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import copy, os\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Computational device\n",
    "# Device will be set to GPU if it is available.(you should install valid Pytorch version with CUDA. Otherwise, it will be computed using CPU)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "DIR = './results/gridsearch16'\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 6000 Test data size: 3000\n"
     ]
    }
   ],
   "source": [
    "SELECT_NORMAL = 2 # Set 2 class as train dataset.\n",
    "trainset.data = trainset.data[trainset.targets == SELECT_NORMAL]\n",
    "trainset.targets = trainset.targets[trainset.targets == SELECT_NORMAL] # Set 2 class as train dataset.\n",
    "\n",
    "test_label = [2,4,6] # Define actual test class that we use\n",
    "actual_testdata = torch.isin(testset.targets, torch.tensor(test_label))\n",
    "testset.data = testset.data[actual_testdata]\n",
    "testset.targets = testset.targets[actual_testdata]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset, batch_size  = 1,\n",
    "    shuffle     = False,num_workers = 2)\n",
    "\n",
    "train_data_size = len(trainset)\n",
    "test_data_size = len(testset)\n",
    "\n",
    "print(\"Train data size:\", train_data_size, \"Test data size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 증강 기법 사용 class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, std=0.1):\n",
    "        super().__init__()\n",
    "        self.std = std\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = x.data.new(x.size()).normal_(0, self.std)\n",
    "            return x + noise\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 배로 Augmentation을 할 것인지 알려주면 해당 배수만큼 Augmentation을 수행하는 클래스\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),                  # 20도는 좀 크고, 15도 이하 권장\n",
    "    transforms.RandomCrop(28, padding=2),           # shift 효과\n",
    "    GaussianNoise(0.1),                          # Gaussian Noise 추가  \n",
    "])\n",
    "\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None, augmentation_factor=1):\n",
    "        '''\n",
    "        dataset: 원본 데이터셋\n",
    "        transform: 증강을 위한 transform\n",
    "        augmentation_factor: 몇 배로 Augmentation (1 포함)\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.augmentation_factor = augmentation_factor\n",
    "        self.original_length = len(dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 전체 데이터 수 = 원본 * 배수\n",
    "        return self.original_length * self.augmentation_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 원본 인덱스\n",
    "        original_idx = idx % self.original_length\n",
    "        x, y = self.dataset[original_idx]\n",
    "\n",
    "        # factor == 1 이거나 첫 번째 패스는 원본 사용\n",
    "        if self.augmentation_factor > 1 and idx >= self.original_length:\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 48000 Val data size: 1200 Test data size: 3000\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 먼저 train과 val로 나누고, train에 대해서만 증강을 적용\n",
    "n_val = int(len(trainset) * 0.2)\n",
    "n_train = len(trainset) - n_val\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "augset, valset = torch.utils.data.random_split(trainset, [n_train, n_val], generator=torch.Generator().manual_seed(2025))\n",
    "\n",
    "augset = AugmentedDataset(augset, transform=transform, augmentation_factor=10) # augmentation_factor = 10\n",
    "# valset은 증강을 적용하지 않음\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = augset, batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,num_workers = 0) \n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = valset, batch_size = BATCH_SIZE,\n",
    "    shuffle     = False,num_workers = 0)\n",
    "\n",
    "# data size check\n",
    "print(\"Train data size:\", len(augset),\"Val data size:\", len(valset),\"Test data size:\", len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 및 Training Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        '''\n",
    "        patience (int): 얼마나 기다릴지\n",
    "        verbose (bool): True일 경우 각 epoch의 loss 출력\n",
    "        delta (float): 개선이 되었다고 인정되는 최소한의 loss\n",
    "        '''\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss # validation loss가 작을수록 좋다고 가정\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 및 loss 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: dict_keys(['Autoencoder', 'CAE', 'CVAE', 'DeepCAE', 'DeepCVAE', 'DeepVAE', 'DenoisingAutoencoder', 'DiffusionUNet', 'GANomaly', 'HybridCAE', 'RobustAutoencoder', 'SimpleDDPM', 'SkipConnectionAutoencoder', 'TransformerAnomalyDetector', 'VAE'])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import model\n",
    "\n",
    "def get_model_classes():\n",
    "    \"\"\"\n",
    "    model 폴더 내에서 nn.Module 기반 클래스만 자동으로 dict로 반환\n",
    "    \"\"\"\n",
    "    model_classes = {}\n",
    "    for k in dir(model):\n",
    "        obj = getattr(model, k)\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj.__module__.startswith('model.'):\n",
    "            model_classes[k] = obj\n",
    "    return model_classes\n",
    "\n",
    "model_classes = {name: cls() for name, cls in get_model_classes().items()}\n",
    "print(\"Available models:\", model_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available reconstruction loss functions: dict_keys(['MSE', 'MSE+Gradient', 'MSE+MS-SSIM', 'Charbonnier+MS-SSIM', 'Charbonnier+Gradient'])\n",
      "Available diffusion loss functions: dict_keys(['MSE', 'MSE+Gradient', 'Charbonnier', 'Charbonnier+Gradient'])\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "# loss function 추천 조합\n",
    "from loss.losses import FlexibleLoss, FlexibleDiffusionLoss\n",
    "\n",
    "reconstruction_loss = {\n",
    "    \"MSE\": FlexibleLoss(mode=\"mse\"),\n",
    "    \"MSE+Gradient\": FlexibleLoss(mode=\"mse+gradient\", beta=1.0, gamma=0.1),\n",
    "    \"MSE+MS-SSIM\": FlexibleLoss(mode=\"mse+ms-ssim\", beta=1.0, alpha=0.3),\n",
    "    \"Charbonnier+MS-SSIM\": FlexibleLoss(mode=\"charbonnier+ms-ssim\", beta=1.0, alpha=0.5),\n",
    "    \"Charbonnier+Gradient\": FlexibleLoss(mode=\"charbonnier+gradient\", beta=1.0, gamma=0.1),\n",
    "}\n",
    "\n",
    "diffusion_loss = {\n",
    "    \"MSE\": FlexibleDiffusionLoss(mode=\"mse\"),\n",
    "    \"MSE+Gradient\": FlexibleDiffusionLoss(mode=\"mse+gradient\", beta=1.0, alpha=0.1),\n",
    "    \"Charbonnier\": FlexibleDiffusionLoss(mode=\"charbonnier\", beta=1.0),\n",
    "    \"Charbonnier+Gradient\": FlexibleDiffusionLoss(mode=\"charbonnier+gradient\", beta=1.0, alpha=0.1)\n",
    "}\n",
    "loss_functions = {\n",
    "    \"reconstruction\": reconstruction_loss,\n",
    "    \"diffusion\": diffusion_loss,\n",
    "}\n",
    "\n",
    "print(\"Available reconstruction loss functions:\", reconstruction_loss.keys())\n",
    "print(\"Available diffusion loss functions:\", diffusion_loss.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Autoencoder has missing checkpoints. Keeping in list.\n",
      "❌ CAE has missing checkpoints. Keeping in list.\n",
      "❌ CVAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepCAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepCVAE has missing checkpoints. Keeping in list.\n",
      "❌ DeepVAE has missing checkpoints. Keeping in list.\n",
      "❌ DenoisingAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ DiffusionUNet has missing checkpoints. Keeping in list.\n",
      "❌ GANomaly has missing checkpoints. Keeping in list.\n",
      "❌ HybridCAE has missing checkpoints. Keeping in list.\n",
      "❌ RobustAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ SimpleDDPM has missing checkpoints. Keeping in list.\n",
      "❌ SkipConnectionAutoencoder has missing checkpoints. Keeping in list.\n",
      "❌ TransformerAnomalyDetector has missing checkpoints. Keeping in list.\n",
      "❌ VAE has missing checkpoints. Keeping in list.\n",
      "Remaining models: dict_keys(['Autoencoder', 'CAE', 'CVAE', 'DeepCAE', 'DeepCVAE', 'DeepVAE', 'DenoisingAutoencoder', 'DiffusionUNet', 'GANomaly', 'HybridCAE', 'RobustAutoencoder', 'SimpleDDPM', 'SkipConnectionAutoencoder', 'TransformerAnomalyDetector', 'VAE'])\n"
     ]
    }
   ],
   "source": [
    "def model_delete(models, loss_functions, checkpoint_dir):\n",
    "    '''\n",
    "    이미 학습된 모델 + loss 조합을 models, loss_functions에서 제거\n",
    "    checkpoint_dir/{model_name}_{loss_name}.pth 존재 여부로 판단\n",
    "    '''\n",
    "    models_to_delete = []\n",
    "\n",
    "    for model_name in list(models.keys()):\n",
    "        # 현재 모델이 사용 가능한 loss 목록\n",
    "        if hasattr(models[model_name], 'T'):\n",
    "            losses = list(loss_functions['diffusion'].keys())\n",
    "        else:\n",
    "            losses = list(loss_functions['reconstruction'].keys())\n",
    "        \n",
    "        # 해당 모델의 모든 loss 조합이 학습되었는지 확인\n",
    "        all_ckpt_exist = all(\n",
    "            os.path.exists(os.path.join(checkpoint_dir, f\"{model_name}_{loss.replace('+','and')}.pth\"))\n",
    "            for loss in losses\n",
    "        )\n",
    "\n",
    "        if all_ckpt_exist:\n",
    "            print(f\"✅ {model_name} all checkpoints exist. Removing from list.\")\n",
    "            models_to_delete.append(model_name)\n",
    "        else:\n",
    "            print(f\"❌ {model_name} has missing checkpoints. Keeping in list.\")\n",
    "    \n",
    "    # 실제 삭제\n",
    "    for model_name in models_to_delete:\n",
    "        del models[model_name]\n",
    "\n",
    "    return models\n",
    "# 모델과 loss function 조합을 삭제\n",
    "model_classes = model_delete(model_classes, loss_functions, DIR)\n",
    "print(\"Remaining models:\", model_classes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch image shape: torch.Size([1024, 1, 28, 28])\n",
      "Train batch label shape: torch.Size([1024])\n",
      "Test batch image shape: torch.Size([1, 1, 28, 28])\n",
      "Test batch label shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of a batch from train_loader and test_loader\n",
    "train_images, train_labels = next(iter(train_loader))\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "\n",
    "print(\"Train batch image shape:\", train_images.shape)\n",
    "print(\"Train batch label shape:\", train_labels.shape)\n",
    "print(\"Test batch image shape:\", test_images.shape)\n",
    "print(\"Test batch label shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Total Models: 15\n",
      "Reconstruction Losses: 5 Diffusion Losses: 4\n",
      "Total Combinations: 74\n",
      "==================================================\n",
      "▶ Training [Autoencoder] with [MSE] (FP16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Autoencoder | MSE (FP16):  11%|█         | 22/200 [05:01<40:24, 13.62s/it]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "# GridSearchTrainerfp16\n",
    "from trainer import GridSearchTrainerFP16, GridSearchTrainer\n",
    "trainer = GridSearchTrainerFP16(\n",
    "    models=model_classes,\n",
    "    criterions_dict=loss_functions,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    n_epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    save_dir=f'{DIR}/checkpoints',\n",
    "    verbose=False, \n",
    "    device=DEVICE,\n",
    "    lr=1e-3 * BATCH_SIZE / 256 # default learning rate for AdamW\n",
    ")\n",
    "results = trainer.run()\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(f'{DIR}/training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>loss</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>save_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.049954</td>\n",
       "      <td>./checkpoints/Autoencoder_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>./checkpoints/CAE_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>./checkpoints/CVAE_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepCAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.037144</td>\n",
       "      <td>./checkpoints/DeepCAE_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeepCVAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>./checkpoints/DeepCVAE_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DenoisingAutoencoder</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>./checkpoints/DenoisingAutoencoder_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiffusionUNet</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>./checkpoints/DiffusionUNet_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GANomaly</td>\n",
       "      <td>MSE</td>\n",
       "      <td>17.122880</td>\n",
       "      <td>./checkpoints/GANomaly_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HybridCAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>./checkpoints/HybridCAE_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RobustAutoencoder</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.048929</td>\n",
       "      <td>./checkpoints/RobustAutoencoder_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SimpleDDPM</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.157383</td>\n",
       "      <td>./checkpoints/SimpleDDPM_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SkipConnectionAutoencoder</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>./checkpoints/SkipConnectionAutoencoder_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TransformerAnomalyDetector</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.270044</td>\n",
       "      <td>./checkpoints/TransformerAnomalyDetector_MSE.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VAE</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>./checkpoints/VAE_MSE.pth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model loss  best_val_loss  \\\n",
       "0                  Autoencoder  MSE       0.049954   \n",
       "1                          CAE  MSE       0.012909   \n",
       "2                         CVAE  MSE       0.001859   \n",
       "3                      DeepCAE  MSE       0.037144   \n",
       "4                     DeepCVAE  MSE       0.000254   \n",
       "5         DenoisingAutoencoder  MSE       0.009787   \n",
       "6                DiffusionUNet  MSE       0.033451   \n",
       "7                     GANomaly  MSE      17.122880   \n",
       "8                    HybridCAE  MSE       0.046011   \n",
       "9            RobustAutoencoder  MSE       0.048929   \n",
       "10                  SimpleDDPM  MSE       0.157383   \n",
       "11   SkipConnectionAutoencoder  MSE       0.002402   \n",
       "12  TransformerAnomalyDetector  MSE       0.270044   \n",
       "13                         VAE  MSE       0.001039   \n",
       "\n",
       "                                           save_path  \n",
       "0                  ./checkpoints/Autoencoder_MSE.pth  \n",
       "1                          ./checkpoints/CAE_MSE.pth  \n",
       "2                         ./checkpoints/CVAE_MSE.pth  \n",
       "3                      ./checkpoints/DeepCAE_MSE.pth  \n",
       "4                     ./checkpoints/DeepCVAE_MSE.pth  \n",
       "5         ./checkpoints/DenoisingAutoencoder_MSE.pth  \n",
       "6                ./checkpoints/DiffusionUNet_MSE.pth  \n",
       "7                     ./checkpoints/GANomaly_MSE.pth  \n",
       "8                    ./checkpoints/HybridCAE_MSE.pth  \n",
       "9            ./checkpoints/RobustAutoencoder_MSE.pth  \n",
       "10                  ./checkpoints/SimpleDDPM_MSE.pth  \n",
       "11   ./checkpoints/SkipConnectionAutoencoder_MSE.pth  \n",
       "12  ./checkpoints/TransformerAnomalyDetector_MSE.pth  \n",
       "13                         ./checkpoints/VAE_MSE.pth  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, checkpoint_dir, val_loader, test_loader, device=None, percentile=0.95, save_dir='./eval_results'):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.percentile = percentile\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        model_class = get_model_classes()[model_name]\n",
    "        model = model_class().to(self.device)\n",
    "        return model\n",
    "\n",
    "    def compute_score(self, model, x):\n",
    "        if hasattr(model, 'T'):\n",
    "            t = torch.randint(0, model.T, (x.size(0),), device=x.device)\n",
    "            noise_pred, noise = model(x, t)\n",
    "            return F.mse_loss(noise_pred, noise, reduction='none').view(x.size(0), -1).mean(dim=1)\n",
    "        output = model(x)\n",
    "        if isinstance(output, tuple):\n",
    "            output = output[0]\n",
    "        return F.mse_loss(output, x, reduction='none').view(x.size(0), -1).mean(dim=1)\n",
    "\n",
    "    def get_scores(self, loader, model):\n",
    "        model.eval()\n",
    "        scores, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(loader, desc=\"Scoring\"):\n",
    "                x = x.to(self.device)\n",
    "                score = self.compute_score(model, x)\n",
    "                scores.append(score.cpu())\n",
    "                labels.append(y.cpu())\n",
    "        return torch.cat(scores).numpy(), torch.cat(labels).numpy()\n",
    "\n",
    "    def run(self):\n",
    "        checkpoint_files = [f for f in os.listdir(self.checkpoint_dir) if f.endswith(\".pth\")]\n",
    "        results = []\n",
    "\n",
    "        for ckpt in checkpoint_files:\n",
    "            print(f\"\\n▶ Evaluating {ckpt}\")\n",
    "\n",
    "            model_name, loss_name = ckpt[:-4].split(\"_\", 1)\n",
    "            model = self.load_model(model_name)\n",
    "            model.load_state_dict(torch.load(os.path.join(self.checkpoint_dir, ckpt)))\n",
    "\n",
    "            val_scores, _ = self.get_scores(self.val_loader, model)\n",
    "            threshold = np.percentile(val_scores, self.percentile * 100)\n",
    "            print(f\" >> Threshold ({self.percentile*100:.0f}%) = {threshold:.4f}\")\n",
    "\n",
    "            test_scores, test_labels = self.get_scores(self.test_loader, model)\n",
    "            test_labels = (test_labels != 2).astype(int)\n",
    "            preds = (test_scores > threshold).astype(int)\n",
    "\n",
    "            auc_score = roc_auc_score(test_labels, test_scores)\n",
    "            precision, recall, _ = precision_recall_curve(test_labels, test_scores)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            f1 = f1_score(test_labels, preds)\n",
    "            acc = accuracy_score(test_labels, preds)  # ⭕ Accuracy 추가\n",
    "\n",
    "            print(f\"ROC-AUC: {auc_score:.4f} | PR-AUC: {pr_auc:.4f} | F1: {f1:.4f} | ACC: {acc:.4f}\")\n",
    "\n",
    "            results.append({\n",
    "                \"checkpoint\": ckpt,\n",
    "                \"threshold\": threshold,\n",
    "                \"roc_auc\": auc_score,\n",
    "                \"pr_auc\": pr_auc,\n",
    "                \"f1\": f1,\n",
    "                \"acc\": acc  # ⭕ 기록\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Evaluating Autoencoder_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 40.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 720.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5332 | PR-AUC: 0.6799 | F1: 0.1028\n",
      "\n",
      "▶ Evaluating CAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 632.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4171 | PR-AUC: 0.6255 | F1: 0.1143\n",
      "\n",
      "▶ Evaluating CVAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 585.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5134 | PR-AUC: 0.6640 | F1: 0.0460\n",
      "\n",
      "▶ Evaluating DeepCAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 638.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4286 | PR-AUC: 0.6079 | F1: 0.0400\n",
      "\n",
      "▶ Evaluating DeepCVAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 590.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5078 | PR-AUC: 0.6662 | F1: 0.0664\n",
      "\n",
      "▶ Evaluating DenoisingAutoencoder_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 19.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 664.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4219 | PR-AUC: 0.6304 | F1: 0.1182\n",
      "\n",
      "▶ Evaluating DiffusionUNet_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 636.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4081 | PR-AUC: 0.6024 | F1: 0.0576\n",
      "\n",
      "▶ Evaluating GANomaly_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:05<00:00, 591.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.3761 | PR-AUC: 0.5971 | F1: 0.0839\n",
      "\n",
      "▶ Evaluating HybridCAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 610.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5142 | PR-AUC: 0.6663 | F1: 0.0769\n",
      "\n",
      "▶ Evaluating RobustAutoencoder_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 42.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 667.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5418 | PR-AUC: 0.6996 | F1: 0.1296\n",
      "\n",
      "▶ Evaluating SimpleDDPM_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 656.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5171 | PR-AUC: 0.6787 | F1: 0.0863\n",
      "\n",
      "▶ Evaluating SkipConnectionAutoencoder_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 624.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4336 | PR-AUC: 0.6287 | F1: 0.0803\n",
      "\n",
      "▶ Evaluating TransformerAnomalyDetector_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:06<00:00, 481.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4930 | PR-AUC: 0.6419 | F1: 0.0355\n",
      "\n",
      "▶ Evaluating VAE_MSE.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 2/2 [00:00<00:00, 44.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Threshold (@95%) = 0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 3000/3000 [00:04<00:00, 680.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5112 | PR-AUC: 0.6633 | F1: 0.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>threshold</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoencoder_MSE.pth</td>\n",
       "      <td>0.088597</td>\n",
       "      <td>0.533179</td>\n",
       "      <td>0.679935</td>\n",
       "      <td>0.102825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAE_MSE.pth</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.417074</td>\n",
       "      <td>0.625503</td>\n",
       "      <td>0.114312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVAE_MSE.pth</td>\n",
       "      <td>0.123979</td>\n",
       "      <td>0.513384</td>\n",
       "      <td>0.663999</td>\n",
       "      <td>0.046043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepCAE_MSE.pth</td>\n",
       "      <td>0.067239</td>\n",
       "      <td>0.428583</td>\n",
       "      <td>0.607922</td>\n",
       "      <td>0.039981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeepCVAE_MSE.pth</td>\n",
       "      <td>0.120728</td>\n",
       "      <td>0.507833</td>\n",
       "      <td>0.666234</td>\n",
       "      <td>0.066382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DenoisingAutoencoder_MSE.pth</td>\n",
       "      <td>0.015244</td>\n",
       "      <td>0.421910</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.118182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiffusionUNet_MSE.pth</td>\n",
       "      <td>0.050046</td>\n",
       "      <td>0.408063</td>\n",
       "      <td>0.602370</td>\n",
       "      <td>0.057574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GANomaly_MSE.pth</td>\n",
       "      <td>0.028873</td>\n",
       "      <td>0.376113</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>0.083877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HybridCAE_MSE.pth</td>\n",
       "      <td>0.083981</td>\n",
       "      <td>0.514245</td>\n",
       "      <td>0.666335</td>\n",
       "      <td>0.076887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RobustAutoencoder_MSE.pth</td>\n",
       "      <td>0.082134</td>\n",
       "      <td>0.541758</td>\n",
       "      <td>0.699636</td>\n",
       "      <td>0.129562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SimpleDDPM_MSE.pth</td>\n",
       "      <td>0.690705</td>\n",
       "      <td>0.517089</td>\n",
       "      <td>0.678690</td>\n",
       "      <td>0.086304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SkipConnectionAutoencoder_MSE.pth</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.433586</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>0.080336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TransformerAnomalyDetector_MSE.pth</td>\n",
       "      <td>0.469455</td>\n",
       "      <td>0.492992</td>\n",
       "      <td>0.641918</td>\n",
       "      <td>0.035492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VAE_MSE.pth</td>\n",
       "      <td>0.119835</td>\n",
       "      <td>0.511229</td>\n",
       "      <td>0.663291</td>\n",
       "      <td>0.054415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            checkpoint  threshold   roc_auc    pr_auc  \\\n",
       "0                  Autoencoder_MSE.pth   0.088597  0.533179  0.679935   \n",
       "1                          CAE_MSE.pth   0.018927  0.417074  0.625503   \n",
       "2                         CVAE_MSE.pth   0.123979  0.513384  0.663999   \n",
       "3                      DeepCAE_MSE.pth   0.067239  0.428583  0.607922   \n",
       "4                     DeepCVAE_MSE.pth   0.120728  0.507833  0.666234   \n",
       "5         DenoisingAutoencoder_MSE.pth   0.015244  0.421910  0.630390   \n",
       "6                DiffusionUNet_MSE.pth   0.050046  0.408063  0.602370   \n",
       "7                     GANomaly_MSE.pth   0.028873  0.376113  0.597055   \n",
       "8                    HybridCAE_MSE.pth   0.083981  0.514245  0.666335   \n",
       "9            RobustAutoencoder_MSE.pth   0.082134  0.541758  0.699636   \n",
       "10                  SimpleDDPM_MSE.pth   0.690705  0.517089  0.678690   \n",
       "11   SkipConnectionAutoencoder_MSE.pth   0.003560  0.433586  0.628710   \n",
       "12  TransformerAnomalyDetector_MSE.pth   0.469455  0.492992  0.641918   \n",
       "13                         VAE_MSE.pth   0.119835  0.511229  0.663291   \n",
       "\n",
       "          f1  \n",
       "0   0.102825  \n",
       "1   0.114312  \n",
       "2   0.046043  \n",
       "3   0.039981  \n",
       "4   0.066382  \n",
       "5   0.118182  \n",
       "6   0.057574  \n",
       "7   0.083877  \n",
       "8   0.076887  \n",
       "9   0.129562  \n",
       "10  0.086304  \n",
       "11  0.080336  \n",
       "12  0.035492  \n",
       "13  0.054415  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(\n",
    "    checkpoint_dir=f'{DIR}/checkpoints',\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=DEVICE,\n",
    "    percentile=0.95,\n",
    "    save_dir=f'{DIR}/eval_results'  # ⭕ 저장할 디렉토리\n",
    ")\n",
    "eval_results = evaluator.run()\n",
    "eval_results.to_csv('{DIR}/eval_results/eval_results.csv', index=False)  # ⭕ CSV로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
