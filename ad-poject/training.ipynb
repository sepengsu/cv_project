{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8b0cc-dc91-4635-8cb5-52e58662c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af804943",
   "metadata": {},
   "source": [
    "### 세팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d106579",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "# Computational device\n",
    "# Device will be set to GPU if it is available.(you should install valid Pytorch version with CUDA. Otherwise, it will be computed using CPU)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cf9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', train     = False,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_NORMAL = 2 # Set 2 class as train dataset.\n",
    "trainset.data = trainset.data[trainset.targets == SELECT_NORMAL]\n",
    "trainset.targets = trainset.targets[trainset.targets == SELECT_NORMAL] # Set 2 class as train dataset.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset, batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,num_workers = 2)\n",
    "\n",
    "test_label = [2,4,6] # Define actual test class that we use\n",
    "actual_testdata = torch.isin(testset.targets, torch.tensor(test_label))\n",
    "testset.data = testset.data[actual_testdata]\n",
    "testset.targets = testset.targets[actual_testdata]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset, batch_size  = 1,\n",
    "    shuffle     = False,num_workers = 2)\n",
    "\n",
    "train_data_size = len(trainset)\n",
    "test_data_size = len(testset)\n",
    "\n",
    "print(\"Train data size:\", train_data_size)\n",
    "print(\"Test data size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d187298",
   "metadata": {},
   "source": [
    "### 모델 및 Training Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5967be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.autoencoder import Autoencoder,Autoencoder2D\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "model = Autoencoder2D().to(DEVICE) # Autoencoder2D is used for 2D data.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE) # AdamW optimizer is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, train_loader):\n",
    "    autoencoder.train()\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        x = x.view(-1, 28*28).to(DEVICE)\n",
    "        y = x.view(-1, 28*28).to(DEVICE) \n",
    "\n",
    "        encoded, decoded = autoencoder(x)\n",
    "\n",
    "        loss = criterion(decoded, y) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process including visualization\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    train(autoencoder, train_loader)\n",
    "\n",
    "    test_x = view_data.to(DEVICE)\n",
    "    _, decoded_data = autoencoder(test_x)\n",
    "\n",
    "    f, a = plt.subplots(2, len(test_label), figsize=(len(test_label), 2))\n",
    "    print(\"[Epoch {}]\".format(epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42dce3",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "THRESHOLDVAL=0.01 # threshold val\n",
    "dic_loss = {'id':[], 'label':[], 'score':[],'normal':[]}\n",
    "\n",
    "count=0\n",
    "for step, (x, label) in enumerate(test_loader):\n",
    "    x = x.view(-1, 28*28).to(DEVICE)\n",
    "    y = x.view(-1, 28*28).to(DEVICE) \n",
    "\n",
    "    encoded, decoded = autoencoder(x)\n",
    "    loss = float(criterion(decoded, y).cpu().detach().numpy())\n",
    "    dic_loss['id'].append(step)\n",
    "    dic_loss['label'].append(int(label==SELECT_NORMAL)) # 1: normal, 0: abnormal\n",
    "    dic_loss['score'].append(loss) # abnormal score\n",
    "    if loss>THRESHOLDVAL: dic_loss['normal'].append('0')\n",
    "    else: dic_loss['normal'].append('1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c634e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gernerating a plot\n",
    "arr_label = np.array(dic_loss['label'])\n",
    "arr_score = np.array(dic_loss['score'])\n",
    "score_min = arr_score.min()\n",
    "score_max = arr_score.max()\n",
    "plt.hist(arr_score[np.where(arr_label == 1)[0]], bins=30, range=(score_min, score_max), alpha=0.5, label='Normal')\n",
    "plt.hist(arr_score[np.where(arr_label == 0)[0]], bins=30, range=(score_min, score_max), alpha=0.5, label='Abnormal')\n",
    "plt.xlabel(\"Anomaly score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axvline(THRESHOLDVAL,0,1, color='red',linestyle='--',linewidth=1)\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating AUROC\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
    "fpr, tpr, thresholds = roc_curve(dic_loss['label'], dic_loss['score'], pos_label=0)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.savefig(\"auroc.png\")\n",
    "plt.show()\n",
    "auroc = auc(fpr, tpr)\n",
    "print(\"AUROC: {}\".format(auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e971b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leveraging the pandas library to convert a dict to a dataframe is more convenient when checking values.\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "df = pd.DataFrame.from_dict(dic_loss)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a46acf-7944-4bf9-9a04-c911c3973fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to submit .csv file to kaggle, dataframe should fit following format\n",
    "# id[1,2,3...,3000], predicted anomalies[0,1,0....,0]\n",
    "\n",
    "# 'pop('score,None')' delete one of the item in dict\n",
    "# 'del df['item']', is also available.\n",
    "\n",
    "# If you try to remove invalid itmes in the dict, message that you set will be returned.\n",
    "# set to None, nothing will be returned\n",
    "dic_loss.pop('score',None)\n",
    "dic_loss.pop('label',None)\n",
    "df = pd.DataFrame.from_dict(dic_loss)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12310bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_csv command will convert your dict to .csv file with the name of your teamnumber\n",
    "# Do not forget to submit the .csv file to kaggle. If you upload .csv file properly to kaggle, you can check your result immediately at the leaderboard.\n",
    "teamnumber = 8 # insert your teamnumber\n",
    "df.to_csv(\"result_team{}.csv\".format(teamnumber), index =False) # Index should be not included in the .csv file.\n",
    "torch.save(autoencoder.state_dict(), 'model_team{}.pth'.format(teamnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb22687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
