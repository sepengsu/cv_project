import torch
import torch.nn as nn

# âœ… SEBlock (Swin attention ê°•í™”ìš©)
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=8):
        super().__init__()
        self.se = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(channels, channels // reduction, kernel_size=1),
            nn.ReLU(),
            nn.Conv2d(channels // reduction, channels, kernel_size=1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        weight = self.se(x)
        return x * weight

# âœ… Swin Encoder
class SwinEncoder(nn.Module):
    def __init__(self, swin_dim=128):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, swin_dim // 2, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),
            nn.Conv2d(swin_dim // 2, swin_dim, kernel_size=3, stride=2, padding=1), nn.LeakyReLU(0.2),
            nn.Conv2d(swin_dim, swin_dim, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),
            nn.Conv2d(swin_dim, swin_dim, kernel_size=3, stride=2, padding=1), nn.LeakyReLU(0.2),
            SEBlock(swin_dim)
        )

    def forward(self, x):
        return self.model(x)

class CNNEncoder(nn.Module):
    def __init__(self, cnn_dim=32):
        super().__init__()
        self.cnn_dim = cnn_dim

        self.model = nn.Sequential(
            nn.Conv2d(1, cnn_dim // 2, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),
            nn.Conv2d(cnn_dim // 2, cnn_dim // 2, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),
            nn.Conv2d(cnn_dim // 2, cnn_dim, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),
        )

        # âœ… ê°•í•œ Bottleneck (cnn_dimì„ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ì  ê³„ì‚°)
        mid_channels_1 = cnn_dim // 2
        mid_channels_2 = cnn_dim // 4
        mid_channels_3 = cnn_dim // 8

        self.bottleneck = nn.Sequential(
            nn.Conv2d(cnn_dim, mid_channels_1, kernel_size=1), nn.ReLU(),   # cnn_dim â†’ //2
            nn.Conv2d(mid_channels_1, mid_channels_2, kernel_size=1), nn.ReLU(), # //2 â†’ //4
            nn.Conv2d(mid_channels_2, mid_channels_3, kernel_size=1), nn.ReLU(), # //4 â†’ //8
            nn.Dropout2d(p=0.1),
            nn.Conv2d(mid_channels_3, mid_channels_2, kernel_size=1), nn.ReLU(), # //8 â†’ //4
            nn.Conv2d(mid_channels_2, mid_channels_1, kernel_size=1), nn.ReLU(), # //4 â†’ //2
            nn.Conv2d(mid_channels_1, cnn_dim, kernel_size=1), nn.ReLU(),    # //2 â†’ cnn_dim
            nn.Conv2d(cnn_dim, mid_channels_1, kernel_size=1), nn.ReLU(),    # cnn_dim â†’ //2
            nn.Conv2d(mid_channels_1, mid_channels_2, kernel_size=1), nn.ReLU(), # //2 â†’ //4
            nn.Conv2d(mid_channels_2, mid_channels_3, kernel_size=1), nn.ReLU(),  # //4 â†’ //8
            nn.Dropout2d(p=0.1),
        )

        # âœ… ê°•í•œ Dropout ì¶”ê°€
        self.dropout = nn.Dropout2d(p=0.6, inplace=False)

    def forward(self, x):
        feat_in = self.model(x)          # (B, cnn_dim, 28, 28)
        feat_out = self.bottleneck(feat_in)
        feat_out = self.dropout(feat_out)

        # âœ… Channel mismatch ë³´ì •
        if feat_in.shape[1] != feat_out.shape[1]:
            feat_in = nn.Conv2d(feat_in.shape[1], feat_out.shape[1], kernel_size=1, bias=False).to(feat_in.device)(feat_in)

        # âœ… Residual ê¸°ë°˜ sharpening
        residual = torch.abs(feat_in - feat_out).clamp(0, 1)
        feat_final = (1.0 - residual) ** 8  # 4ì œê³± sharpening ê°•í™”

        return feat_final

# âœ… SwinCNNHybridAE
class SwinCNNHybridAE(nn.Module):
    def __init__(self, swin_dim=128, cnn_dim=32, latent_noise_std=0.25,noise_std=0.25,mask_threshold = 0.5):
        super().__init__()
        self.latent_noise_std = latent_noise_std
        self.swin_dim = swin_dim
        self.cnn_dim = cnn_dim
        self.noise_std = noise_std
        self.mask_threshold = mask_threshold
        self.swin_encoder = SwinEncoder(swin_dim=swin_dim)
        self.cnn_encoder = CNNEncoder(cnn_dim=cnn_dim)

        self.swin_upsample = nn.Upsample(size=(28, 28), mode='nearest')

        self.dropout = nn.Dropout2d(p=0.6, inplace=False)

        # âœ… Conv bottleneck: in_channels = swin_dim + cnn_dim
        self.latent_conv = nn.Sequential(
            nn.Conv2d(swin_dim + cnn_dim//8, swin_dim, kernel_size=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(swin_dim, swin_dim, kernel_size=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(swin_dim, swin_dim, kernel_size=1),
            nn.LeakyReLU(0.2),
        )

        # âœ… Decoder
        self.decoder = nn.Sequential(
            nn.Conv2d(swin_dim, swin_dim // 2, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(4, swin_dim // 2),
            nn.LeakyReLU(0.2),

            nn.Conv2d(swin_dim // 2, swin_dim // 4, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(4, swin_dim // 4),
            nn.LeakyReLU(0.2),

            nn.Conv2d(swin_dim // 4, 32, kernel_size=3, stride=1, padding=1),
            nn.GroupNorm(4, 32),
            nn.LeakyReLU(0.2),

            nn.Conv2d(32, 1, kernel_size=3, padding=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        swin_feat = self.swin_encoder(x)          # (B, swin_dim, 7,7)
        swin_feat = self.swin_upsample(swin_feat)  # (B, swin_dim, 28,28)

        cnn_feat = self.cnn_encoder(x)             # (B, cnn_dim, 28,28)
        cnn_feat = self.dropout(cnn_feat)

        # ğŸ”¥ Mask ìƒì„±
        swin_mask = swin_feat.mean(dim=1, keepdim=True)  # (B, 1, 28, 28)
        cnn_mask = cnn_feat.mean(dim=1, keepdim=True)    # (B, 1, 28, 28)

        # ğŸ”¥ Mask ì°¨ì´ ê³„ì‚°
        mask_diff = torch.abs(swin_mask - cnn_mask)

        # ğŸ”¥ Selective Noise Injection
        noise = torch.randn_like(cnn_feat) * self.noise_std
        inject_mask = (mask_diff > self.mask_threshold).float() # maskì— ë”°ë¼ noise ì¶”ê°€
        cnn_feat = cnn_feat + noise * inject_mask  # selective noise ì¶”ê°€

        # ğŸ”¥ concat í›„ latent bottleneck
        feat_concat = torch.cat([swin_feat, cnn_feat], dim=1)
        latent = self.latent_conv(feat_concat)

        # ğŸ”¥ latent noise ì¶”ê°€
        if self.training and self.latent_noise_std > 0:
            noise_latent = torch.randn_like(latent) * self.latent_noise_std
            latent = latent + noise_latent

        x_hat = self.decoder(latent)
        return x_hat