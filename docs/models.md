# ğŸ“– Models Documentation

ë³¸ ë¬¸ì„œëŠ” ë³¸ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ 15ì¢…ì˜ ëª¨ë¸ êµ¬ì¡°, íŠ¹ì§•, ëª©ì  ë° ì°¸ê³  ë¬¸í—Œì„ ì •ë¦¬í•œ ìë£Œì…ë‹ˆë‹¤.

---

## 1ï¸ Autoencoder (AE)
- **ëª¨ë¸ íŠ¹ì§•**: ê°€ì¥ ê¸°ë³¸ì ì¸ Autoencoder êµ¬ì¡°
- **ëª©ì **: ì…ë ¥ ì´ë¯¸ì§€ ë³µì› ë° ì¬êµ¬ì„± ê¸°ë°˜ ì´ìƒíƒì§€
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**: 
    - Encoder-Decoder êµ¬ì¡°
    - MSE ê¸°ë°˜ Reconstruction Loss
- **Structure**: FC ê¸°ë°˜ ê°„ë‹¨í•œ Encoder + Decoder
- **ì°¸ê³  ë¬¸í—Œ**: 
    - Hinton, G.E., & Salakhutdinov, R.R. (2006). Reducing the Dimensionality of Data with Neural Networks.

---

## 2ï¸ CAE (Convolutional Autoencoder)
- **ëª¨ë¸ íŠ¹ì§•**: CNN ê¸°ë°˜ AE
- **ëª©ì **: ì´ë¯¸ì§€ì˜ ì§€ì—­ì  íŠ¹ì§• ë³´ì¡´ ë° ì¬êµ¬ì„±
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Convolution + Pooling ê¸°ë°˜ Encoder
    - Deconvolution ê¸°ë°˜ Decoder
- **Structure**: CNN Encoder â†’ CNN Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Masci, J. et al. (2011). Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction.

---

## 3ï¸ CVAE (Convolutional Variational Autoencoder)
- **ëª¨ë¸ íŠ¹ì§•**: CNN + VAE ê²°í•©
- **ëª©ì **: ì ì¬ ê³µê°„ ë¶„í¬ í•™ìŠµ + ì´ë¯¸ì§€ ì¬êµ¬ì„±
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Convolution ê¸°ë°˜ Encoder
    - Sampling (Reparameterization Trick)
    - Convolutional Decoder
- **Structure**: Conv Encoder â†’ Latent z â†’ Conv Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Kingma, D.P., & Welling, M. (2013). Auto-Encoding Variational Bayes.

---

## 4ï¸ DeepCAE
- **ëª¨ë¸ íŠ¹ì§•**: Deepí•œ CNN ê¸°ë°˜ AE
- **ëª©ì **: ë” ë³µì¡í•œ Feature Extraction
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - ê¹Šì€ Convolution Layer
- **Structure**: Deep Conv Encoder â†’ Deep Conv Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Xu, X. et al. (2018). Anomaly Detection Based on Deep Convolutional Autoencoder.

---

## 5ï¸ DeepCVAE
- **ëª¨ë¸ íŠ¹ì§•**: Deep Convolution + VAE
- **ëª©ì **: Deep êµ¬ì¡°ë¥¼ í†µí•œ íš¨ê³¼ì ì¸ latent distribution í•™ìŠµ
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Deep Conv + Reparameterization
- **Structure**: Deep Conv Encoder â†’ z â†’ Deep Conv Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Sohn, K. et al. (2015). Learning Structured Output Representation using Deep Conditional Generative Models.

---

## 6ï¸ DeepVAE
- **ëª¨ë¸ íŠ¹ì§•**: Fully Connected ê¸°ë°˜ Deep VAE
- **ëª©ì **: MNIST ë“± low-res datasetì— ì í•©
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - FC + Reparameterization
- **Structure**: FC Encoder â†’ z â†’ FC Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Kingma, D.P., & Welling, M. (2013). Auto-Encoding Variational Bayes.

---

## 7ï¸ DenoisingAutoencoder
- **ëª¨ë¸ íŠ¹ì§•**: Noise Robust AE
- **ëª©ì **: ë…¸ì´ì¦ˆ í™˜ê²½ì—ì„œë„ ì •ìƒì ì¸ ë³µì›
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - ì…ë ¥ ì´ë¯¸ì§€ì— ë…¸ì´ì¦ˆ ì¶”ê°€ í›„ ë³µì› í•™ìŠµ
- **Structure**: AE êµ¬ì¡°
- **ì°¸ê³  ë¬¸í—Œ**:
    - Vincent, P. et al. (2008). Extracting and Composing Robust Features with Denoising Autoencoders.

---

## 8ï¸ DiffusionUNet
- **ëª¨ë¸ íŠ¹ì§•**: UNet êµ¬ì¡° ê¸°ë°˜ DDPM
- **ëª©ì **: Diffusion ê¸°ë°˜ Anomaly Detection
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - UNet + Denoising Score Matching
- **Structure**: UNet
- **ì°¸ê³  ë¬¸í—Œ**:
    - Ho, J. et al. (2020). Denoising Diffusion Probabilistic Models.

---

## 9ï¸ GANomaly
- **ëª¨ë¸ íŠ¹ì§•**: GAN + AE
- **ëª©ì **: Adversarial Training ê¸°ë°˜ ì´ìƒíƒì§€
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Generator (AE ì—­í• )
    - Discriminator
    - Adversarial Loss + Reconstruction Loss
- **Structure**: Generator (AE) + Discriminator
- **ì°¸ê³  ë¬¸í—Œ**:
    - AkÃ§ay, S. et al. (2018). GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training.

---

## 10 HybridCAE
- **ëª¨ë¸ íŠ¹ì§•**: Hybrid CNN êµ¬ì¡° ì ìš© AE
- **ëª©ì **: Local + Global feature capture
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Multi-Scale Encoder
- **Structure**: CNN ê¸°ë°˜ Hybrid Encoder + Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - ìì²´ ì„¤ê³„

---

## 11 RobustAutoencoder
- **ëª¨ë¸ íŠ¹ì§•**: Robust AE
- **ëª©ì **: ì´ìƒì¹˜ì— ê°•ê±´í•œ AE
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Robust Principal Component Analysis (RPCA) ì•„ì´ë””ì–´ ê¸°ë°˜
- **Structure**: FC ê¸°ë°˜ Encoder, Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Zhou, C. et al. (2017). Anomaly Detection with Robust Deep Autoencoders.

---

## 12 SimpleDDPM
- **ëª¨ë¸ íŠ¹ì§•**: Simple DDPM êµ¬ì¡°
- **ëª©ì **: Lightweight diffusion model
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Simplified DDPM Pipeline
- **Structure**: Simple UNet backbone
- **ì°¸ê³  ë¬¸í—Œ**:
    - Ho, J. et al. (2020). Denoising Diffusion Probabilistic Models.

---

## 13 SkipConnectionAutoencoder
- **ëª¨ë¸ íŠ¹ì§•**: Skip Connection ì ìš© AE
- **ëª©ì **: AE + Residual Learning
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Encoder Featureë¥¼ Decoderì— Skip ì—°ê²°
- **Structure**: AE + Skip Connection
- **ì°¸ê³  ë¬¸í—Œ**:
    - Mao, X. et al. (2016). Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections.

---

## 14 TransformerAnomalyDetector
- **ëª¨ë¸ íŠ¹ì§•**: ViT ê¸°ë°˜ Anomaly Detection
- **ëª©ì **: Global Context ê¸°ë°˜ ì´ìƒíƒì§€
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Vision Transformer Encoder
- **Structure**: Transformer Encoder â†’ Reconstruction
- **ì°¸ê³  ë¬¸í—Œ**:
    - Dosovitskiy, A. et al. (2020). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.

---

## 15 VAE
- **ëª¨ë¸ íŠ¹ì§•**: ê°€ì¥ ê¸°ë³¸ì ì¸ VAE
- **ëª©ì **: Latent Representation ê¸°ë°˜ ì´ìƒíƒì§€
- **ì£¼ìš” function ë° ì•„ì´ë””ì–´**:
    - Reparameterization Trick
- **Structure**: FC Encoder â†’ z â†’ FC Decoder
- **ì°¸ê³  ë¬¸í—Œ**:
    - Kingma, D.P., & Welling, M. (2013). Auto-Encoding Variational Bayes.

